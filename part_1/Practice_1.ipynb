{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6dff42",
   "metadata": {},
   "source": [
    "## Тема “Предобработка текста с помощью Python”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c7707",
   "metadata": {},
   "source": [
    "Осуществим предобработку данных с Твиттера, чтобы очищенные данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания. Для работы объединим train_df и test_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "412d3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb773b",
   "metadata": {},
   "source": [
    "#### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6bf3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_tweets.csv',encoding='utf-8')\n",
    "df_test = pd.read_csv('test_tweets.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f017c8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>6965</td>\n",
       "      <td>0</td>\n",
       "      <td>â #mexico headline inflation declined to -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31697</th>\n",
       "      <td>31698</td>\n",
       "      <td>0</td>\n",
       "      <td>@user it's impoant to make someone  , and it'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>4782</td>\n",
       "      <td>0</td>\n",
       "      <td>father's day to the most amazing. dad love y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>4284</td>\n",
       "      <td>0</td>\n",
       "      <td>@user the perfect mother's day gift. #florche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>17895</td>\n",
       "      <td>0</td>\n",
       "      <td>tummy to the rescue! #baby  #tummy #natural #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "6964    6965      0   â #mexico headline inflation declined to -0...\n",
       "31697  31698      0   @user it's impoant to make someone  , and it'...\n",
       "4781    4782      0    father's day to the most amazing. dad love y...\n",
       "4283    4284      0   @user the perfect mother's day gift. #florche...\n",
       "17894  17895      0   tummy to the rescue! #baby  #tummy #natural #..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ce930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31962, 3), (17197, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d16729f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet\n",
       "0   1   @user when a father is dysfunctional and is s..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop('label', axis=1)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020aaff3",
   "metadata": {},
   "source": [
    "#### Обьеденим датафреймы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15907531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298361d9",
   "metadata": {},
   "source": [
    "    1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию:\n",
    "    - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    "    - для для замены @user на пробел, необходимо использовать re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f60c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab3cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_words_user(pattern,text):\n",
    "    return re.sub(pattern,'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86232900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba88568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(del_words_user)(pattern,df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c787e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849a088",
   "metadata": {},
   "source": [
    "2. Изменим регистр твитов на нижний с помощью .lower()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ec2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lower(text):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021d1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = df['tweet'].apply(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5159304",
   "metadata": {},
   "source": [
    "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4451cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем все сокращения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36813264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_apost (text):\n",
    "    list_apos = []\n",
    "    for i in range(text.shape[0]-1):\n",
    "        list_apos.extend(re.findall('\\w*\\'\\w*', text[i]))\n",
    "        list_apos = list(set(list_apos))\n",
    "    return list_apos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c52fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"memoriam'\",\n",
       " \"88'\",\n",
       " \"when's\",\n",
       " \"terrorism'\",\n",
       " \"somethin'\",\n",
       " \"doin'\",\n",
       " \"hockey's\",\n",
       " \"victoria's\",\n",
       " \"shy'boiâ\",\n",
       " \"studio's\",\n",
       " \"anthony's\",\n",
       " \"hong's\",\n",
       " \"iftar's\",\n",
       " \"'the\",\n",
       " \"globalfundwomen's\",\n",
       " \"rubik's\",\n",
       " \"'darkest\",\n",
       " \"petercarey's\",\n",
       " \"couldn't\",\n",
       " \"rajan's\",\n",
       " \"joking'\",\n",
       " \"itshe's\",\n",
       " \"kingdom's\",\n",
       " \"mickler's\",\n",
       " \"'ve\",\n",
       " \"wendyhuntbatch's\",\n",
       " \"mornin'\",\n",
       " \"1930s'\",\n",
       " \"missin'\",\n",
       " \"buzzin'\",\n",
       " \"who've\",\n",
       " \"kid's\",\n",
       " \"school's\",\n",
       " \"hayley's\",\n",
       " \"blacks'\",\n",
       " \"mainez's\",\n",
       " \"'duh\",\n",
       " \"'rest\",\n",
       " \"o'toole\",\n",
       " \"finlay's\",\n",
       " \"mexico's\",\n",
       " \"lyin'\",\n",
       " \"'lynch\",\n",
       " \"'70\",\n",
       " \"megan's\",\n",
       " \"dayton's\",\n",
       " \"grass'\",\n",
       " \"parent's\",\n",
       " \"joy'\",\n",
       " \"satan's\",\n",
       " \"nigeria's\",\n",
       " \"'dolled\",\n",
       " \"chewin'\",\n",
       " \"dino's\",\n",
       " \"too'\",\n",
       " \"dad's\",\n",
       " \"boy's\",\n",
       " \"green's\",\n",
       " \"yunho's\",\n",
       " \"'moshpit\",\n",
       " \"races'\",\n",
       " \"year's\",\n",
       " \"'udta\",\n",
       " \"world'\",\n",
       " \"dmaughn's\",\n",
       " \"young'sâ\",\n",
       " \"bihday's\",\n",
       " \"'making\",\n",
       " \"god'sâ\",\n",
       " \"mp'â\",\n",
       " \"'really\",\n",
       " \"'launched\",\n",
       " \"tuesday's\",\n",
       " \"jahn's\",\n",
       " \"shannon's\",\n",
       " \"diego's\",\n",
       " \"intelligence'\",\n",
       " \"jordan's\",\n",
       " \"jo'\",\n",
       " \"nando's\",\n",
       " \"'charming\",\n",
       " \"monday's\",\n",
       " \"i'll\",\n",
       " \"'scientists\",\n",
       " \"glamours'\",\n",
       " \"beer'in\",\n",
       " \"ellie's\",\n",
       " \"morning's\",\n",
       " \"ny'er\",\n",
       " \"can'tbeleive\",\n",
       " \"andretti's\",\n",
       " \"bust'\",\n",
       " \"all_pikeg's\",\n",
       " \"betty's\",\n",
       " \"shoy's\",\n",
       " \"ball'\",\n",
       " \"ramadan's\",\n",
       " \"paddy's\",\n",
       " \"iqbal's\",\n",
       " \"johnson's\",\n",
       " \"'britainland\",\n",
       " \"16'\",\n",
       " \"aren't\",\n",
       " \"c'est\",\n",
       " \"gej's\",\n",
       " \"lappy's\",\n",
       " \"70's\",\n",
       " \"swift's\",\n",
       " \"'dark\",\n",
       " \"chairman's\",\n",
       " \"'out\",\n",
       " \"who's\",\n",
       " \"arabs'\",\n",
       " \"rolf's\",\n",
       " \"that'll\",\n",
       " \"bringin'â\",\n",
       " \"yall's\",\n",
       " \"'bit\",\n",
       " \"government's\",\n",
       " \"billy's\",\n",
       " \"other's\",\n",
       " \"church's\",\n",
       " \"waltdisney's\",\n",
       " \"god'slove\",\n",
       " \"meeee'\",\n",
       " \"roommate's\",\n",
       " \"i'manadultnow\",\n",
       " \"fav's\",\n",
       " \"pushin'em\",\n",
       " \"omarosa's\",\n",
       " \"you'reâ\",\n",
       " \"nra's\",\n",
       " \"marx's\",\n",
       " \"wherever'\",\n",
       " \"'spizza\",\n",
       " \"va's\",\n",
       " \"slam's\",\n",
       " \"son's\",\n",
       " \"tony's\",\n",
       " \"lion's\",\n",
       " \"'leave\",\n",
       " \"winner'\",\n",
       " \"v2's\",\n",
       " \"x'\",\n",
       " \"tags'\",\n",
       " \"england's\",\n",
       " \"domino's\",\n",
       " \"loveca's\",\n",
       " \"nothing's\",\n",
       " \"'08\",\n",
       " \"shakey's\",\n",
       " \"stanton's\",\n",
       " \"'build\",\n",
       " \"room's\",\n",
       " \"judge's\",\n",
       " \"industry's\",\n",
       " \"refugee's\",\n",
       " \"southwest's\",\n",
       " \"'15\",\n",
       " \"driver's\",\n",
       " \"linkedin'sh\",\n",
       " \"endings'\",\n",
       " \"ole'\",\n",
       " \"mcdonald's\",\n",
       " \"euna102794's\",\n",
       " \"family's\",\n",
       " \"group's\",\n",
       " \"'seussical\",\n",
       " \"dean's\",\n",
       " \"america's\",\n",
       " \"'t\",\n",
       " \"shooting'\",\n",
       " \"b's\",\n",
       " \"mom's\",\n",
       " \"sony's\",\n",
       " \"university's\",\n",
       " \"mercenary's\",\n",
       " \"'giak\",\n",
       " \"fathers'\",\n",
       " \"bbq'\",\n",
       " \"jimmy's\",\n",
       " \"swimming'\",\n",
       " \"mma's\",\n",
       " \"jungkook's\",\n",
       " \"scotland's\",\n",
       " \"'bilious\",\n",
       " \"'stick\",\n",
       " \"tavana's\",\n",
       " \"they've\",\n",
       " \"'answer\",\n",
       " \"river's\",\n",
       " \"tupac's\",\n",
       " \"'â\",\n",
       " \"crisafulli's\",\n",
       " \"'don\",\n",
       " \"beauty's\",\n",
       " \"'anti\",\n",
       " \"year'\",\n",
       " \"father'sday\",\n",
       " \"raggin'\",\n",
       " \"'what\",\n",
       " \"editor's\",\n",
       " \"boyfriend's\",\n",
       " \"7'33\",\n",
       " \"'on\",\n",
       " \"call'\",\n",
       " \"23'rd\",\n",
       " \"james's\",\n",
       " \"bear's\",\n",
       " \"light'\",\n",
       " \"shark's\",\n",
       " \"'scarlet\",\n",
       " \"psychologist's\",\n",
       " \"piktocha's\",\n",
       " \"italy'\",\n",
       " \"runner's\",\n",
       " \"warning'\",\n",
       " \"fool's\",\n",
       " \"'club\",\n",
       " \"'narrow\",\n",
       " \"responsible'\",\n",
       " \"kkk'\",\n",
       " \"someone's\",\n",
       " \"abc's\",\n",
       " \"'launch\",\n",
       " \"chili's\",\n",
       " \"fathers'day\",\n",
       " \"webster's\",\n",
       " \"week's\",\n",
       " \"ally's\",\n",
       " \"g'mâ\",\n",
       " \"1950's\",\n",
       " \"'acche\",\n",
       " \"'sorry\",\n",
       " \"'sleeps\",\n",
       " \"odor's\",\n",
       " \"hossein's\",\n",
       " \"gfriend's\",\n",
       " \"i'mbroke\",\n",
       " \"we'rent\",\n",
       " \"'bout\",\n",
       " \"mother's\",\n",
       " \"'need\",\n",
       " \"surprise'\",\n",
       " \"person's\",\n",
       " \"rupemurdoch's\",\n",
       " \"prayer's\",\n",
       " \"oscar's\",\n",
       " \"3's\",\n",
       " \"don't\",\n",
       " \"l'pool\",\n",
       " \"'one\",\n",
       " \"l'vivs\",\n",
       " \"'suppoers\",\n",
       " \"shelter'\",\n",
       " \"game's\",\n",
       " \"wit'em\",\n",
       " \"ppl's\",\n",
       " \"wife'\",\n",
       " \"azendea's\",\n",
       " \"journal's\",\n",
       " \"others'\",\n",
       " \"nashie's\",\n",
       " \"sun's\",\n",
       " \"forever's\",\n",
       " \"thinker's\",\n",
       " \"1930's\",\n",
       " \"l'impact\",\n",
       " \"she'll\",\n",
       " \"'fun\",\n",
       " \"july'16\",\n",
       " \"why's\",\n",
       " \"girls'\",\n",
       " \"atlanta's\",\n",
       " \"'93\",\n",
       " \"'brown\",\n",
       " \"'understanding\",\n",
       " \"hope's\",\n",
       " \"princess'\",\n",
       " \"happen'\",\n",
       " \"l'm\",\n",
       " \"hangin'\",\n",
       " \"room'\",\n",
       " \"dance'\",\n",
       " \"menchie's\",\n",
       " \"he'll\",\n",
       " \"zzzzzz's\",\n",
       " \"saibaba's\",\n",
       " \"shumpe's\",\n",
       " \"enablin'\",\n",
       " \"saturday's\",\n",
       " \"swimmer's\",\n",
       " \"company's\",\n",
       " \"bihday'\",\n",
       " \"ko's\",\n",
       " \"humanity'\",\n",
       " \"players'\",\n",
       " \"farel's\",\n",
       " \"'bambi\",\n",
       " \"harrisburg's\",\n",
       " \"m'y\",\n",
       " \"hill's\",\n",
       " \"karma's\",\n",
       " \"2's\",\n",
       " \"today's\",\n",
       " \"yu's\",\n",
       " \"christina's\",\n",
       " \"hairdresser's\",\n",
       " \"good'\",\n",
       " \"king's\",\n",
       " \"'statement\",\n",
       " \"globe's\",\n",
       " \"'jokes\",\n",
       " \"'catch\",\n",
       " \"'racism\",\n",
       " \"peter's\",\n",
       " \"stephcurry's\",\n",
       " \"'\",\n",
       " \"ms's\",\n",
       " \"'91\",\n",
       " \"photograph's\",\n",
       " \"divide'nrule\",\n",
       " \"summer's\",\n",
       " \"here'\",\n",
       " \"allan's\",\n",
       " \"hands'\",\n",
       " \"refugee'\",\n",
       " \"cano's\",\n",
       " \"we'll\",\n",
       " \"that's\",\n",
       " \"andrea's\",\n",
       " \"team's\",\n",
       " \"'how\",\n",
       " \"everyone'\",\n",
       " \"nate's\",\n",
       " \"denny's\",\n",
       " \"'calm\",\n",
       " \"din'\",\n",
       " \"grimmie's\",\n",
       " \"'unique\",\n",
       " \"cousin's\",\n",
       " \"journalists'\",\n",
       " \"neutral'\",\n",
       " \"7ather's\",\n",
       " \"victims'ð\",\n",
       " \"'coward\",\n",
       " \"friend's\",\n",
       " \"murderer's\",\n",
       " \"canada's\",\n",
       " \"g'boro\",\n",
       " \"'damn\",\n",
       " \"track's\",\n",
       " \"lyin'crookedhillary\",\n",
       " \"get's\",\n",
       " \"clearly'\",\n",
       " \"90's\",\n",
       " \"grammaw's\",\n",
       " \"possible'\",\n",
       " \"'gender\",\n",
       " \"carlpaladino's\",\n",
       " \"d'etre\",\n",
       " \"'money\",\n",
       " \"gimmie'\",\n",
       " \"fare'\",\n",
       " \"ali's\",\n",
       " \"odin's\",\n",
       " \"papa's\",\n",
       " \"ma'ana\",\n",
       " \"nori's\",\n",
       " \"littleun's\",\n",
       " \"facebookin'\",\n",
       " \"'blood\",\n",
       " \"dispatched'\",\n",
       " \"jackson's\",\n",
       " \"adele's\",\n",
       " \"should've\",\n",
       " \"daddy'sâ\",\n",
       " \"they'll\",\n",
       " \"eaton's\",\n",
       " \"herschlag's\",\n",
       " \"obama's\",\n",
       " \"limiting'\",\n",
       " \"u'll\",\n",
       " \"'dodgy\",\n",
       " \"kardashian's\",\n",
       " \"curry's\",\n",
       " \"suck's\",\n",
       " \"attenborough's\",\n",
       " \"thereptilezoofv's\",\n",
       " \"disney's\",\n",
       " \"biscuit'\",\n",
       " \"'site\",\n",
       " \"apple's\",\n",
       " \"emma's\",\n",
       " \"life's\",\n",
       " \"w'd\",\n",
       " \"kai's\",\n",
       " \"flippin'\",\n",
       " \"boots'\",\n",
       " \"'beating\",\n",
       " \"wings'\",\n",
       " \"don't_leave_me\",\n",
       " \"bali's\",\n",
       " \"emily's\",\n",
       " \"natalia's\",\n",
       " \"'cranky\",\n",
       " \"c'mon\",\n",
       " \"'mindset\",\n",
       " \"'situation\",\n",
       " \"sins'\",\n",
       " \"prosecution's\",\n",
       " \"iknowthingsuthinkidon'tknow\",\n",
       " \"'sweekend\",\n",
       " \"'man\",\n",
       " \"champ's\",\n",
       " \"cont'd\",\n",
       " \"movie's\",\n",
       " \"gov't\",\n",
       " \"'negative\",\n",
       " \"japan's\",\n",
       " \"donald's\",\n",
       " \"father'sdayquotes\",\n",
       " \"man's\",\n",
       " \"wingin'\",\n",
       " \"rod's\",\n",
       " \"'lucky\",\n",
       " \"treatment'\",\n",
       " \"whiteness'\",\n",
       " \"i'ma\",\n",
       " \"'democracy\",\n",
       " \"'dictatorial\",\n",
       " \"spoing's\",\n",
       " \"shared'\",\n",
       " \"shuckin'andjivin\",\n",
       " \"balett's\",\n",
       " \"devil's\",\n",
       " \"everything's\",\n",
       " \"'excellence\",\n",
       " \"they'd\",\n",
       " \"voice'\",\n",
       " \"right'\",\n",
       " \"angie's\",\n",
       " \"'no\",\n",
       " \"laptop's\",\n",
       " \"'2\",\n",
       " \"int'l\",\n",
       " \"jo's\",\n",
       " \"'unrecognizable\",\n",
       " \"grillin'\",\n",
       " \"client's\",\n",
       " \"mark's\",\n",
       " \"there're\",\n",
       " \"uber's\",\n",
       " \"50's\",\n",
       " \"kate's\",\n",
       " \"microsoft's\",\n",
       " \"quebec's\",\n",
       " \"ange's\",\n",
       " \"szymanowski's\",\n",
       " \"left's\",\n",
       " \"kellogg's\",\n",
       " \"'this\",\n",
       " \"existing'\",\n",
       " \"toothbrush'\",\n",
       " \"ioc's\",\n",
       " \"bobby's\",\n",
       " \"'never\",\n",
       " \"obama'\",\n",
       " \"shooter's\",\n",
       " \"might've\",\n",
       " \"'popped\",\n",
       " \"day'\",\n",
       " \"'butt\",\n",
       " \"igwe's\",\n",
       " \"papi's\",\n",
       " \"ma'likrichmond\",\n",
       " \"bf's\",\n",
       " \"blowin'\",\n",
       " \"boy'\",\n",
       " \"europe'\",\n",
       " \"year'sâ\",\n",
       " \"intl'l\",\n",
       " \"david's\",\n",
       " \"singhania's\",\n",
       " \"noy's\",\n",
       " \"policy's\",\n",
       " \"wilhelm's\",\n",
       " \"t'aime\",\n",
       " \"zoo's\",\n",
       " \"salesperson'\",\n",
       " \"'2day\",\n",
       " \"'80s\",\n",
       " \"night's\",\n",
       " \"robeson's\",\n",
       " \"nature's\",\n",
       " \"jts88's\",\n",
       " \"were'nt\",\n",
       " \"instagram's\",\n",
       " \"where's\",\n",
       " \"'directly\",\n",
       " \"brother's\",\n",
       " \"venue's\",\n",
       " \"pastor's\",\n",
       " \"yo're\",\n",
       " \"beyonce'\",\n",
       " \"2'\",\n",
       " \"'oj\",\n",
       " \"granddaughter's\",\n",
       " \"don'tgetoutmuch\",\n",
       " \"he's\",\n",
       " \"cma's\",\n",
       " \"'remain\",\n",
       " \"whites'\",\n",
       " \"'rachel\",\n",
       " \"'happiest\",\n",
       " \"f'd\",\n",
       " \"end'\",\n",
       " \"ayah's\",\n",
       " \"wouldn't\",\n",
       " \"'if\",\n",
       " \"geoffrey's\",\n",
       " \"lafnwebseries's\",\n",
       " \"aidan's\",\n",
       " \"'corpse\",\n",
       " \"ivana's\",\n",
       " \"hop's\",\n",
       " \"'boom\",\n",
       " \"humanity's\",\n",
       " \"asians'\",\n",
       " \"mla's\",\n",
       " \"gingrich's\",\n",
       " \"knott's\",\n",
       " \"bee's\",\n",
       " \"this's\",\n",
       " \"neighbor's\",\n",
       " \"'brad\",\n",
       " \"mary's\",\n",
       " \"'ka\",\n",
       " \"o'\",\n",
       " \"alfredo's\",\n",
       " \"arin's\",\n",
       " \"here's\",\n",
       " \"else's\",\n",
       " \"charmar's\",\n",
       " \"'white\",\n",
       " \"wendy's\",\n",
       " \"yelchin's\",\n",
       " \"gandhi's\",\n",
       " \"isabelle's\",\n",
       " \"thursday's\",\n",
       " \"lamy's\",\n",
       " \"vandal's\",\n",
       " \"kapitbahay's\",\n",
       " \"nigger'\",\n",
       " \"lg's\",\n",
       " \"clinton's\",\n",
       " \"bean's\",\n",
       " \"l'italien\",\n",
       " \"'d\",\n",
       " \"50'x6\",\n",
       " \"everyone's\",\n",
       " \"grandma's\",\n",
       " \"ac's\",\n",
       " \"roxy's\",\n",
       " \"'office\",\n",
       " \"excellence'\",\n",
       " \"chereb's\",\n",
       " \"repoer's\",\n",
       " \"'needs\",\n",
       " \"skin'\",\n",
       " \"d'ae\",\n",
       " \"unnie's\",\n",
       " \"frank's\",\n",
       " \"dustin's\",\n",
       " \"harry's\",\n",
       " \"bingo'\",\n",
       " \"jocox's\",\n",
       " \"'plurality\",\n",
       " \"experience'\",\n",
       " \"'devastating\",\n",
       " \"stage'\",\n",
       " \"bulldog's\",\n",
       " \"oblast'\",\n",
       " \"weren't\",\n",
       " \"4'\",\n",
       " \"girl's\",\n",
       " \"woman'\",\n",
       " \"cav's\",\n",
       " \"rapper's\",\n",
       " \"'today\",\n",
       " \"co's\",\n",
       " \"dragon's\",\n",
       " \"livin'thing\",\n",
       " \"rotterdam's\",\n",
       " \"x'mas\",\n",
       " \"in't\",\n",
       " \"chicago's\",\n",
       " \"roadtrippin'\",\n",
       " \"'ddd\",\n",
       " \"asshole's\",\n",
       " \"hero's\",\n",
       " \"they're\",\n",
       " \"justin's\",\n",
       " \"'risk\",\n",
       " \"takin'\",\n",
       " \"chocies'\",\n",
       " \"one's\",\n",
       " \"y'allâ\",\n",
       " \"that'snotalife\",\n",
       " \"jacqueline's\",\n",
       " \"'franchisor\",\n",
       " \"ke's\",\n",
       " \"ped's\",\n",
       " \"'omg\",\n",
       " \"meng's\",\n",
       " \"'liberals\",\n",
       " \"katie's\",\n",
       " \"'hang\",\n",
       " \"link's\",\n",
       " \"child'\",\n",
       " \"jews'\",\n",
       " \"side'\",\n",
       " \"'raw\",\n",
       " \"adel's\",\n",
       " \"another's\",\n",
       " \"un's\",\n",
       " \"hadn't\",\n",
       " \"didn't\",\n",
       " \"muppet's\",\n",
       " \"wrong'\",\n",
       " \"owl's\",\n",
       " \"d'banj\",\n",
       " \"cameron's\",\n",
       " \"ma'u\",\n",
       " \"'ks\",\n",
       " \"'pink\",\n",
       " \"p's\",\n",
       " \"dollar's\",\n",
       " \"'fairness\",\n",
       " \"fiddler's\",\n",
       " \"chica's\",\n",
       " \"officer's\",\n",
       " \"star'\",\n",
       " \"hashmi's\",\n",
       " \"'opinion\",\n",
       " \"workers'\",\n",
       " \"fall's\",\n",
       " \"hea's\",\n",
       " \"mitchy'\",\n",
       " \"s'mores\",\n",
       " \"'spiritual\",\n",
       " \"mf's\",\n",
       " \"'selling\",\n",
       " \"'rude\",\n",
       " \"halo's\",\n",
       " \"can'tmiss\",\n",
       " \"sunshine'\",\n",
       " \"reptile'\",\n",
       " \"father'sâ\",\n",
       " \"'murderers\",\n",
       " \"jane's\",\n",
       " \"mp's\",\n",
       " \"lucky'\",\n",
       " \"hrc's\",\n",
       " \"'neener\",\n",
       " \"servin'\",\n",
       " \"franky's\",\n",
       " \"i'm\",\n",
       " \"james'\",\n",
       " \"laughin'\",\n",
       " \"'heads\",\n",
       " \"wave's\",\n",
       " \"levendale's\",\n",
       " \"kitty's\",\n",
       " \"'merica\",\n",
       " \"f's\",\n",
       " \"'can\",\n",
       " \"bollywood's\",\n",
       " \"'why\",\n",
       " \"'dog\",\n",
       " \"trippin'\",\n",
       " \"state's\",\n",
       " \"anna's\",\n",
       " \"ev'rybody\",\n",
       " \"people'\",\n",
       " \"'coach\",\n",
       " \"f'n\",\n",
       " \"ma'am\",\n",
       " \"obama'more\",\n",
       " \"kanye's\",\n",
       " \"i've\",\n",
       " \"hater's\",\n",
       " \"puppy's\",\n",
       " \"customers'\",\n",
       " \"'grateful\",\n",
       " \"takashi's\",\n",
       " \"model's\",\n",
       " \"america'\",\n",
       " \"daddy'swatchingclosely\",\n",
       " \"civilian's\",\n",
       " \"'experimentation\",\n",
       " \"politician's\",\n",
       " \"cleveland's\",\n",
       " \"e's\",\n",
       " \"'constrained\",\n",
       " \"it'\",\n",
       " \"corey's\",\n",
       " \"park's\",\n",
       " \"haven't\",\n",
       " \"fung's\",\n",
       " \"'animals\",\n",
       " \"'live\",\n",
       " \"semitism'\",\n",
       " \"jessica's\",\n",
       " \"stepfather's\",\n",
       " \"lies'\",\n",
       " \"macgregor's\",\n",
       " \"imm'ts\",\n",
       " \"feelin'\",\n",
       " \"body'\",\n",
       " \"gyal's\",\n",
       " \"'kuy\",\n",
       " \"sunrise'\",\n",
       " \"can't\",\n",
       " \"hasn't\",\n",
       " \"universal's\",\n",
       " \"'big\",\n",
       " \"'is\",\n",
       " \"can'tsmilewithoutyou\",\n",
       " \"felicita'\",\n",
       " \"do'\",\n",
       " \"'see\",\n",
       " \"jenny's\",\n",
       " \"blain's\",\n",
       " \"berkowitz's\",\n",
       " \"'star\",\n",
       " \"blake's\",\n",
       " \"jazza's\",\n",
       " \"tempest'\",\n",
       " \"shitheads'\",\n",
       " \"jack's\",\n",
       " \"shinhye's\",\n",
       " \"t'\",\n",
       " \"'radical\",\n",
       " \"love'\",\n",
       " \"broadway's\",\n",
       " \"'treading\",\n",
       " \"you'd\",\n",
       " \"talkin'\",\n",
       " \"'cheerful\",\n",
       " \"'alt\",\n",
       " \"p7's\",\n",
       " \"'right\",\n",
       " \"drumpf's\",\n",
       " \"we're\",\n",
       " \"daughter's\",\n",
       " \"'you\",\n",
       " \"charlespaladino's\",\n",
       " \"'racist\",\n",
       " \"phone's\",\n",
       " \"trump's\",\n",
       " \"madison's\",\n",
       " \"'hate\",\n",
       " \"facebook's\",\n",
       " \"'new\",\n",
       " \"'happiness\",\n",
       " \"bachoichoi's\",\n",
       " \"m's\",\n",
       " \"eve's\",\n",
       " \"it's\",\n",
       " \"dave'\",\n",
       " \"hobi's\",\n",
       " \"'gunshot\",\n",
       " \"man'\",\n",
       " \"lover's\",\n",
       " \"shepherd's\",\n",
       " \"bernie's\",\n",
       " \"leo's\",\n",
       " \"'fast\",\n",
       " \"'fallout\",\n",
       " \"katee's\",\n",
       " \"messiha's\",\n",
       " \"gold's\",\n",
       " \"r's\",\n",
       " \"people's\",\n",
       " \"i'mout\",\n",
       " \"'fit\",\n",
       " \"badly'\",\n",
       " \"'deadliest\",\n",
       " \"father's\",\n",
       " \"elevenses'\",\n",
       " \"lee's\",\n",
       " \"fuck's\",\n",
       " \"'f\",\n",
       " \"matchup's\",\n",
       " \"thank'\",\n",
       " \"husband's\",\n",
       " \"serpent's\",\n",
       " \"s'cute\",\n",
       " \"coaches'\",\n",
       " \"'voice\",\n",
       " \"'tisð\",\n",
       " \"'stay\",\n",
       " \"'happy\",\n",
       " \"be'\",\n",
       " \"h's\",\n",
       " \"'festival\",\n",
       " \"'ð\",\n",
       " \"o'holy\",\n",
       " \"make'em\",\n",
       " \"option'\",\n",
       " \"'futile\",\n",
       " \"15's\",\n",
       " \"we'd\",\n",
       " \"pj's\",\n",
       " \"aists'\",\n",
       " \"w'end\",\n",
       " \"sam's\",\n",
       " \"'great\",\n",
       " \"blog's\",\n",
       " \"o'clock\",\n",
       " \"pm's\",\n",
       " \"filter's\",\n",
       " \"glasto'\",\n",
       " \"don'tcare\",\n",
       " \"'goodluck\",\n",
       " \"go's\",\n",
       " \"scam'\",\n",
       " \"come'\",\n",
       " \"question'\",\n",
       " \"paladino's\",\n",
       " \"thank's\",\n",
       " \"'ll\",\n",
       " \"n'at\",\n",
       " \"would've\",\n",
       " \"live's\",\n",
       " \"'where\",\n",
       " \"hunt's\",\n",
       " \"who'snotopenminded\",\n",
       " \"sant'agnese\",\n",
       " \"chuck'\",\n",
       " \"worries'\",\n",
       " \"fuckin'\",\n",
       " \"max's\",\n",
       " \"moanin'\",\n",
       " \"__luicalibre__'s\",\n",
       " \"'incitement\",\n",
       " \"'followed\",\n",
       " \"orlando's\",\n",
       " \"'element\",\n",
       " \"mathew'\",\n",
       " \"victims'\",\n",
       " \"cm's\",\n",
       " \"pavillion's\",\n",
       " \"aap's\",\n",
       " \"world's\",\n",
       " \"'monsters\",\n",
       " \"vi's\",\n",
       " \"parade's\",\n",
       " \"i'mlovingit\",\n",
       " \"nigga's\",\n",
       " \"b'day\",\n",
       " \"13'\",\n",
       " \"tomorrow's\",\n",
       " \"boc's\",\n",
       " \"keithellison's\",\n",
       " \"m'am\",\n",
       " \"tonight's\",\n",
       " \"u've\",\n",
       " \"'everything\",\n",
       " \"cmt's\",\n",
       " \"'game\",\n",
       " \"lol'd\",\n",
       " \"phareel's\",\n",
       " \"'just\",\n",
       " \"apament's\",\n",
       " \"'your\",\n",
       " \"west's\",\n",
       " \"a'm\",\n",
       " \"'ing\",\n",
       " \"carnegie's\",\n",
       " \"it'll\",\n",
       " \"'hood\",\n",
       " \"'an\",\n",
       " \"'brand\",\n",
       " \"thing'\",\n",
       " \"howe's\",\n",
       " \"you've\",\n",
       " \"june's\",\n",
       " \"y'all\",\n",
       " \"singer's\",\n",
       " \"'whiny\",\n",
       " \"'political\",\n",
       " \"hatchling's\",\n",
       " \"timer's\",\n",
       " \"'family\",\n",
       " \"adults'\",\n",
       " \"u're\",\n",
       " \"women's\",\n",
       " \"'4\",\n",
       " \"jaxon's\",\n",
       " \"there'\",\n",
       " \"epi's\",\n",
       " \"'hello\",\n",
       " \"grandmother's\",\n",
       " \"i'mdeafâ\",\n",
       " \"baby's\",\n",
       " \"pihoo's\",\n",
       " \"n's\",\n",
       " \"astro's\",\n",
       " \"brooke's\",\n",
       " \"hillaryclinton's\",\n",
       " \"dada's\",\n",
       " \"'stirrups\",\n",
       " \"nobody's\",\n",
       " \"cuis'\",\n",
       " \"you'\",\n",
       " \"spelling's\",\n",
       " \"dalton's\",\n",
       " \"'stop\",\n",
       " \"bear'\",\n",
       " \"ueketta's\",\n",
       " \"we've\",\n",
       " \"d'antonio\",\n",
       " \"'own\",\n",
       " \"y'alls\",\n",
       " \"happyfather'sdayð\",\n",
       " \"'loose\",\n",
       " \"jock's\",\n",
       " \"d'you\",\n",
       " \"'cause\",\n",
       " \"queen's\",\n",
       " \"andrewbogut's\",\n",
       " \"ne'er\",\n",
       " \"g'day\",\n",
       " \"caesar's\",\n",
       " \"oldfield's\",\n",
       " \"both'\",\n",
       " \"israel's\",\n",
       " \"saira's\",\n",
       " \"that'd\",\n",
       " \"brooklyn's\",\n",
       " \"cristofori's\",\n",
       " \"use'\",\n",
       " \"society's\",\n",
       " \"'m\",\n",
       " \"evening's\",\n",
       " \"sainsbury's\",\n",
       " \"fella's\",\n",
       " \"don'tknowwhattodo\",\n",
       " \"shope's\",\n",
       " \"'easy\",\n",
       " \"ranveer's\",\n",
       " \"employee's\",\n",
       " \"'hacker\",\n",
       " \"o'halloran\",\n",
       " \"mum's\",\n",
       " \"alex's\",\n",
       " \"kilwin's\",\n",
       " \"annie'\",\n",
       " \"space's\",\n",
       " \"wrath's\",\n",
       " \"sheryl's\",\n",
       " \"'tis\",\n",
       " \"day's\",\n",
       " \"india's\",\n",
       " \"suarez's\",\n",
       " \"city's\",\n",
       " \"'suit\",\n",
       " \"president's\",\n",
       " \"can'tstopsmiling\",\n",
       " \"erhu's\",\n",
       " \"thinking'\",\n",
       " \"norfolk's\",\n",
       " \"tails's\",\n",
       " \"'til\",\n",
       " \"'ed\",\n",
       " \"child's\",\n",
       " \"baltimore's\",\n",
       " \"ranjitbawa's\",\n",
       " \"des'tee\",\n",
       " \"pt's\",\n",
       " \"professional'\",\n",
       " \"con't\",\n",
       " \"democrat's\",\n",
       " \"office'\",\n",
       " \"l'a\",\n",
       " \"dawn's\",\n",
       " \"physics'\",\n",
       " \"tragicallyhip's\",\n",
       " \"nephew's\",\n",
       " \"nath's\",\n",
       " \"'shopped\",\n",
       " \"'gif\",\n",
       " \"pharrell's\",\n",
       " \"ramsay's\",\n",
       " \"ocharley's\",\n",
       " \"'feel\",\n",
       " \"'bee\",\n",
       " \"mo'nique\",\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apostrophe_text = find_apost(df.tweet)\n",
    "apostrophe_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6802daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_text.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e51c461b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " \"'08\",\n",
       " \"'12\",\n",
       " \"'15\",\n",
       " \"'16\",\n",
       " \"'17\",\n",
       " \"'2\",\n",
       " \"'20\",\n",
       " \"'2day\",\n",
       " \"'3\",\n",
       " \"'4\",\n",
       " \"'70\",\n",
       " \"'80s\",\n",
       " \"'91\",\n",
       " \"'93\",\n",
       " \"'a\",\n",
       " \"'acche\",\n",
       " \"'actionable\",\n",
       " \"'all\",\n",
       " \"'alt\",\n",
       " \"'an\",\n",
       " \"'animals\",\n",
       " \"'answer\",\n",
       " \"'anti\",\n",
       " \"'bambi\",\n",
       " \"'beating\",\n",
       " \"'because\",\n",
       " \"'bee\",\n",
       " \"'beyond\",\n",
       " \"'big\",\n",
       " \"'bilious\",\n",
       " \"'bit\",\n",
       " \"'blood\",\n",
       " \"'boom\",\n",
       " \"'bout\",\n",
       " \"'brad\",\n",
       " \"'brand\",\n",
       " \"'breakfast\",\n",
       " \"'britainland\",\n",
       " \"'brown\",\n",
       " \"'build\",\n",
       " \"'building\",\n",
       " \"'butt\",\n",
       " \"'calm\",\n",
       " \"'can\",\n",
       " \"'catch\",\n",
       " \"'cause\",\n",
       " \"'ceified\",\n",
       " \"'cept\",\n",
       " \"'charming\",\n",
       " \"'check\",\n",
       " \"'cheerful\",\n",
       " \"'club\",\n",
       " \"'coach\",\n",
       " \"'constrained\",\n",
       " \"'corpse\",\n",
       " \"'coward\",\n",
       " \"'coz\",\n",
       " \"'cranky\",\n",
       " \"'culture\",\n",
       " \"'d\",\n",
       " \"'damn\",\n",
       " \"'dark\",\n",
       " \"'darkest\",\n",
       " \"'ddd\",\n",
       " \"'deadliest\",\n",
       " \"'death\",\n",
       " \"'democracy\",\n",
       " \"'devastating\",\n",
       " \"'dictatorial\",\n",
       " \"'directly\",\n",
       " \"'dishevelled\",\n",
       " \"'do\",\n",
       " \"'dodgy\",\n",
       " \"'dog\",\n",
       " \"'dolled\",\n",
       " \"'dolphins\",\n",
       " \"'domestic\",\n",
       " \"'don\",\n",
       " \"'dreaming\",\n",
       " \"'duh\",\n",
       " \"'easy\",\n",
       " \"'ed\",\n",
       " \"'element\",\n",
       " \"'em\",\n",
       " \"'everything\",\n",
       " \"'excellence\",\n",
       " \"'experimentation\",\n",
       " \"'f\",\n",
       " \"'fairness\",\n",
       " \"'fake\",\n",
       " \"'fallout\",\n",
       " \"'family\",\n",
       " \"'far\",\n",
       " \"'fast\",\n",
       " \"'feel\",\n",
       " \"'festival\",\n",
       " \"'finally\",\n",
       " \"'fit\",\n",
       " \"'followed\",\n",
       " \"'follows\",\n",
       " \"'for\",\n",
       " \"'foreign\",\n",
       " \"'franchisor\",\n",
       " \"'friends\",\n",
       " \"'fun\",\n",
       " \"'funko\",\n",
       " \"'futile\",\n",
       " \"'game\",\n",
       " \"'gender\",\n",
       " \"'giak\",\n",
       " \"'gif\",\n",
       " \"'goodluck\",\n",
       " \"'gorilla\",\n",
       " \"'grateful\",\n",
       " \"'great\",\n",
       " \"'gunshot\",\n",
       " \"'gweh\",\n",
       " \"'hacker\",\n",
       " \"'hang\",\n",
       " \"'happiest\",\n",
       " \"'happiness\",\n",
       " \"'happy\",\n",
       " \"'harry\",\n",
       " \"'has\",\n",
       " \"'hate\",\n",
       " \"'heads\",\n",
       " \"'hello\",\n",
       " \"'hood\",\n",
       " \"'how\",\n",
       " \"'i\",\n",
       " \"'if\",\n",
       " \"'im_weird69\",\n",
       " \"'incitement\",\n",
       " \"'ing\",\n",
       " \"'is\",\n",
       " \"'islamic\",\n",
       " \"'it\",\n",
       " \"'jokes\",\n",
       " \"'journo\",\n",
       " \"'just\",\n",
       " \"'ka\",\n",
       " \"'keyed\",\n",
       " \"'kill\",\n",
       " \"'ks\",\n",
       " \"'kuy\",\n",
       " \"'launch\",\n",
       " \"'launched\",\n",
       " \"'leader\",\n",
       " \"'leave\",\n",
       " \"'les\",\n",
       " \"'liberals\",\n",
       " \"'liv\",\n",
       " \"'live\",\n",
       " \"'ll\",\n",
       " \"'loose\",\n",
       " \"'loved\",\n",
       " \"'lucky\",\n",
       " \"'lunch\",\n",
       " \"'lynch\",\n",
       " \"'m\",\n",
       " \"'make\",\n",
       " \"'making\",\n",
       " \"'male\",\n",
       " \"'man\",\n",
       " \"'marbleous\",\n",
       " \"'merica\",\n",
       " \"'mic\",\n",
       " \"'mindset\",\n",
       " \"'minigiraffe\",\n",
       " \"'money\",\n",
       " \"'monsters\",\n",
       " \"'moshpit\",\n",
       " \"'murderers\",\n",
       " \"'muslims\",\n",
       " \"'my\",\n",
       " \"'n\",\n",
       " \"'narrow\",\n",
       " \"'need\",\n",
       " \"'needs\",\n",
       " \"'neener\",\n",
       " \"'negative\",\n",
       " \"'never\",\n",
       " \"'new\",\n",
       " \"'no\",\n",
       " \"'nobody\",\n",
       " \"'non\",\n",
       " \"'oaks\",\n",
       " \"'office\",\n",
       " \"'oj\",\n",
       " \"'omg\",\n",
       " \"'on\",\n",
       " \"'one\",\n",
       " \"'opinion\",\n",
       " \"'orange\",\n",
       " \"'out\",\n",
       " \"'owie\",\n",
       " \"'own\",\n",
       " \"'pearl\",\n",
       " \"'pink\",\n",
       " \"'plurality\",\n",
       " \"'political\",\n",
       " \"'popped\",\n",
       " \"'possible\",\n",
       " \"'prince\",\n",
       " \"'problem\",\n",
       " \"'rachel\",\n",
       " \"'racism\",\n",
       " \"'racist\",\n",
       " \"'radical\",\n",
       " \"'rat\",\n",
       " \"'raw\",\n",
       " \"'re\",\n",
       " \"'really\",\n",
       " \"'remain\",\n",
       " \"'rest\",\n",
       " \"'reverse\",\n",
       " \"'revolution\",\n",
       " \"'right\",\n",
       " \"'risk\",\n",
       " \"'rude\",\n",
       " \"'run\",\n",
       " \"'s\",\n",
       " \"'sad\",\n",
       " \"'scarlet\",\n",
       " \"'scientists\",\n",
       " \"'sday\",\n",
       " \"'see\",\n",
       " \"'selling\",\n",
       " \"'seussical\",\n",
       " \"'shopped\",\n",
       " \"'site\",\n",
       " \"'situation\",\n",
       " \"'sleeps\",\n",
       " \"'snowed\",\n",
       " \"'someone\",\n",
       " \"'sorry\",\n",
       " \"'spiritual\",\n",
       " \"'spizza\",\n",
       " \"'star\",\n",
       " \"'statement\",\n",
       " \"'stay\",\n",
       " \"'stick\",\n",
       " \"'stirrups\",\n",
       " \"'stop\",\n",
       " \"'suit\",\n",
       " \"'suppoers\",\n",
       " \"'surprise\",\n",
       " \"'sweekend\",\n",
       " \"'system\",\n",
       " \"'t\",\n",
       " \"'tail\",\n",
       " \"'terrifying\",\n",
       " \"'the\",\n",
       " \"'this\",\n",
       " \"'til\",\n",
       " \"'tis\",\n",
       " \"'tisð\",\n",
       " \"'today\",\n",
       " \"'too\",\n",
       " \"'treading\",\n",
       " \"'turned\",\n",
       " \"'udta\",\n",
       " \"'understanding\",\n",
       " \"'unique\",\n",
       " \"'unrecognizable\",\n",
       " \"'ve\",\n",
       " \"'voice\",\n",
       " \"'vulgar\",\n",
       " \"'we\",\n",
       " \"'what\",\n",
       " \"'when\",\n",
       " \"'where\",\n",
       " \"'whiny\",\n",
       " \"'white\",\n",
       " \"'who\",\n",
       " \"'why\",\n",
       " \"'wish\",\n",
       " \"'you\",\n",
       " \"'your\",\n",
       " \"'â\",\n",
       " \"'ð\",\n",
       " \"1000's\",\n",
       " \"13'\",\n",
       " \"14's\",\n",
       " \"15'5\",\n",
       " \"15's\",\n",
       " \"16'\",\n",
       " \"1930's\",\n",
       " \"1930s'\",\n",
       " \"1950's\",\n",
       " \"1970's\",\n",
       " \"2'\",\n",
       " \"2's\",\n",
       " \"23'rd\",\n",
       " \"3's\",\n",
       " \"4'\",\n",
       " \"50's\",\n",
       " \"50'x6\",\n",
       " \"6'8\",\n",
       " \"60's\",\n",
       " \"7'33\",\n",
       " \"70's\",\n",
       " \"7ather's\",\n",
       " \"80's\",\n",
       " \"88'\",\n",
       " \"9's\",\n",
       " \"90's\",\n",
       " \"__luicalibre__'s\",\n",
       " \"a'm\",\n",
       " \"a's\",\n",
       " \"aap's\",\n",
       " \"abc's\",\n",
       " \"abusive'\",\n",
       " \"ac's\",\n",
       " \"acc's\",\n",
       " \"adel's\",\n",
       " \"adele's\",\n",
       " \"adults'\",\n",
       " \"africa's\",\n",
       " \"aging's\",\n",
       " \"aidan's\",\n",
       " \"ain't\",\n",
       " \"aists'\",\n",
       " \"aldub's\",\n",
       " \"alex's\",\n",
       " \"alfredo's\",\n",
       " \"ali's\",\n",
       " \"all'\",\n",
       " \"all_pikeg's\",\n",
       " \"allan's\",\n",
       " \"allow's\",\n",
       " \"ally's\",\n",
       " \"alzheimer's\",\n",
       " \"amazon's\",\n",
       " \"amelia's\",\n",
       " \"america'\",\n",
       " \"america's\",\n",
       " \"amodu's\",\n",
       " \"an'\",\n",
       " \"anderson's\",\n",
       " \"andrea's\",\n",
       " \"andretti's\",\n",
       " \"andrew's\",\n",
       " \"andrewbogut's\",\n",
       " \"ange's\",\n",
       " \"angie's\",\n",
       " \"anna's\",\n",
       " \"annie'\",\n",
       " \"another's\",\n",
       " \"anthony's\",\n",
       " \"apament's\",\n",
       " \"apple's\",\n",
       " \"arabs'\",\n",
       " \"arby's\",\n",
       " \"aren't\",\n",
       " \"arin's\",\n",
       " \"armin's\",\n",
       " \"asians'\",\n",
       " \"asshole's\",\n",
       " \"astro's\",\n",
       " \"atlanta's\",\n",
       " \"attempt'\",\n",
       " \"attenborough's\",\n",
       " \"attorney's\",\n",
       " \"au'revoir\",\n",
       " \"austin's\",\n",
       " \"ayah's\",\n",
       " \"azendea's\",\n",
       " \"b'coz\",\n",
       " \"b'day\",\n",
       " \"b's\",\n",
       " \"baby's\",\n",
       " \"bachoichoi's\",\n",
       " \"badly'\",\n",
       " \"balett's\",\n",
       " \"bali's\",\n",
       " \"ball'\",\n",
       " \"baltimore's\",\n",
       " \"base's\",\n",
       " \"bastards'\",\n",
       " \"bbc2's\",\n",
       " \"bbq'\",\n",
       " \"be'\",\n",
       " \"beach's\",\n",
       " \"bean's\",\n",
       " \"bear'\",\n",
       " \"bear's\",\n",
       " \"beauty's\",\n",
       " \"bee's\",\n",
       " \"beer'in\",\n",
       " \"beginning'\",\n",
       " \"bellamy's\",\n",
       " \"ben's\",\n",
       " \"berkowitz's\",\n",
       " \"bernie's\",\n",
       " \"betty's\",\n",
       " \"beyonce'\",\n",
       " \"bf's\",\n",
       " \"bff's\",\n",
       " \"big's\",\n",
       " \"bihday'\",\n",
       " \"bihday's\",\n",
       " \"billy's\",\n",
       " \"bingo'\",\n",
       " \"biscuit'\",\n",
       " \"black's\",\n",
       " \"blacks'\",\n",
       " \"blain's\",\n",
       " \"blake's\",\n",
       " \"bland's\",\n",
       " \"blog's\",\n",
       " \"blowin'\",\n",
       " \"bo's\",\n",
       " \"boards'\",\n",
       " \"bobby's\",\n",
       " \"boc's\",\n",
       " \"body'\",\n",
       " \"boingo's\",\n",
       " \"bollywood's\",\n",
       " \"boots'\",\n",
       " \"borounitedu10's\",\n",
       " \"both'\",\n",
       " \"boy'\",\n",
       " \"boy's\",\n",
       " \"boyfriend's\",\n",
       " \"branding'\",\n",
       " \"bringin'â\",\n",
       " \"broadway's\",\n",
       " \"brooke's\",\n",
       " \"brooklyn's\",\n",
       " \"brother's\",\n",
       " \"buandmax's\",\n",
       " \"buddha's\",\n",
       " \"bulldog's\",\n",
       " \"bust'\",\n",
       " \"buzzfeed's\",\n",
       " \"buzzin'\",\n",
       " \"c'est\",\n",
       " \"c'mon\",\n",
       " \"c'onference\",\n",
       " \"c3's\",\n",
       " \"caesar's\",\n",
       " \"call'\",\n",
       " \"called'\",\n",
       " \"cameron's\",\n",
       " \"can't\",\n",
       " \"can'tbeleive\",\n",
       " \"can'tmiss\",\n",
       " \"can'tsleep\",\n",
       " \"can'tsmilewithoutyou\",\n",
       " \"can'tstopsmiling\",\n",
       " \"can'ttrusthim\",\n",
       " \"can'twait\",\n",
       " \"can'tâ\",\n",
       " \"canada'\",\n",
       " \"canada's\",\n",
       " \"cano's\",\n",
       " \"capelli's\",\n",
       " \"captains'\",\n",
       " \"carlpaladino's\",\n",
       " \"carnegie's\",\n",
       " \"cat's\",\n",
       " \"cav's\",\n",
       " \"chaani's\",\n",
       " \"chairman's\",\n",
       " \"champ's\",\n",
       " \"change'\",\n",
       " \"changed'\",\n",
       " \"charlespaladino's\",\n",
       " \"charlie'\",\n",
       " \"charmar's\",\n",
       " \"chereb's\",\n",
       " \"chewin'\",\n",
       " \"chica's\",\n",
       " \"chicago's\",\n",
       " \"child'\",\n",
       " \"child's\",\n",
       " \"children's\",\n",
       " \"chili's\",\n",
       " \"chillin'\",\n",
       " \"chilllin'\",\n",
       " \"china's\",\n",
       " \"chocies'\",\n",
       " \"christina's\",\n",
       " \"christmas's\",\n",
       " \"chuck'\",\n",
       " \"church's\",\n",
       " \"city's\",\n",
       " \"civilian's\",\n",
       " \"clearly'\",\n",
       " \"cleveland's\",\n",
       " \"client's\",\n",
       " \"clinton's\",\n",
       " \"cm's\",\n",
       " \"cma's\",\n",
       " \"cmt's\",\n",
       " \"co's\",\n",
       " \"coaches'\",\n",
       " \"colinshaw's\",\n",
       " \"com'on\",\n",
       " \"come'\",\n",
       " \"company's\",\n",
       " \"complaining'\",\n",
       " \"con't\",\n",
       " \"confused'\",\n",
       " \"cont'd\",\n",
       " \"corey's\",\n",
       " \"could've\",\n",
       " \"couldn't\",\n",
       " \"country's\",\n",
       " \"county's\",\n",
       " \"cousin's\",\n",
       " \"coward's\",\n",
       " \"coworker's\",\n",
       " \"cox's\",\n",
       " \"craig's\",\n",
       " \"criminal's\",\n",
       " \"crisafulli's\",\n",
       " \"cristofori's\",\n",
       " \"cruz's\",\n",
       " \"cuis'\",\n",
       " \"curry's\",\n",
       " \"customers'\",\n",
       " \"d'ae\",\n",
       " \"d'antonio\",\n",
       " \"d'awwwww\",\n",
       " \"d'banj\",\n",
       " \"d'etre\",\n",
       " \"d's\",\n",
       " \"d'usse\",\n",
       " \"d'you\",\n",
       " \"da's\",\n",
       " \"dad's\",\n",
       " \"dada's\",\n",
       " \"daddy's\",\n",
       " \"daddy'swatchingclosely\",\n",
       " \"daddy'sâ\",\n",
       " \"dalton's\",\n",
       " \"dance'\",\n",
       " \"darwin's\",\n",
       " \"daughter's\",\n",
       " \"dave'\",\n",
       " \"david's\",\n",
       " \"dawn's\",\n",
       " \"day'\",\n",
       " \"day's\",\n",
       " \"dayton's\",\n",
       " \"dean's\",\n",
       " \"democrat's\",\n",
       " \"dench's\",\n",
       " \"denny's\",\n",
       " \"des'tee\",\n",
       " \"destinee's\",\n",
       " \"devil's\",\n",
       " \"dexter's\",\n",
       " \"dhani's\",\n",
       " \"did't\",\n",
       " \"didn't\",\n",
       " \"diego's\",\n",
       " \"din'\",\n",
       " \"dino's\",\n",
       " \"disney's\",\n",
       " \"dispatched'\",\n",
       " \"district's\",\n",
       " \"diva's\",\n",
       " \"divide'nrule\",\n",
       " \"dmaughn's\",\n",
       " \"do'\",\n",
       " \"doesn't\",\n",
       " \"dogmeetsfamily's\",\n",
       " \"doin'\",\n",
       " \"dollar's\",\n",
       " \"domino's\",\n",
       " \"don's\",\n",
       " \"don't\",\n",
       " \"don't_leave_me\",\n",
       " \"don'tcare\",\n",
       " \"don'tgetoutmuch\",\n",
       " \"don'tknowwhattodo\",\n",
       " \"don'tð\",\n",
       " \"donald's\",\n",
       " \"donaldtrump's\",\n",
       " \"doofus'\",\n",
       " \"dragon's\",\n",
       " \"driver's\",\n",
       " \"drivers'\",\n",
       " \"drs'\",\n",
       " \"drumpf's\",\n",
       " \"dustin's\",\n",
       " \"duty'\",\n",
       " \"dvd's\",\n",
       " \"dvr'd\",\n",
       " \"e's\",\n",
       " \"eah'\",\n",
       " \"eah's\",\n",
       " \"easy'\",\n",
       " \"eaton's\",\n",
       " \"editor's\",\n",
       " \"elevenses'\",\n",
       " \"ellie's\",\n",
       " \"else's\",\n",
       " \"em's\",\n",
       " \"emily's\",\n",
       " \"emma's\",\n",
       " \"employee's\",\n",
       " \"enablin'\",\n",
       " \"end'\",\n",
       " \"endings'\",\n",
       " \"enemy's\",\n",
       " \"england's\",\n",
       " \"epi's\",\n",
       " \"erhu's\",\n",
       " \"euna102794's\",\n",
       " \"euro's\",\n",
       " \"europe'\",\n",
       " \"ev'rybody\",\n",
       " \"eve's\",\n",
       " \"evening's\",\n",
       " \"everybody's\",\n",
       " \"everyone'\",\n",
       " \"everyone's\",\n",
       " \"everything's\",\n",
       " \"evil's\",\n",
       " \"evolution's\",\n",
       " \"excellence'\",\n",
       " \"exeter's\",\n",
       " \"existing'\",\n",
       " \"exo's\",\n",
       " \"experience'\",\n",
       " \"f'd\",\n",
       " \"f'ing\",\n",
       " \"f'n\",\n",
       " \"f's\",\n",
       " \"fa's\",\n",
       " \"facebook's\",\n",
       " \"facebookin'\",\n",
       " \"fall's\",\n",
       " \"family's\",\n",
       " \"farahdhukai's\",\n",
       " \"fare'\",\n",
       " \"farel's\",\n",
       " \"father's\",\n",
       " \"father's_day\",\n",
       " \"father'sday\",\n",
       " \"father'sdayquotes\",\n",
       " \"father'sâ\",\n",
       " \"fathers'\",\n",
       " \"fathers'day\",\n",
       " \"fathersday'\",\n",
       " \"fav's\",\n",
       " \"feelin'\",\n",
       " \"feeling'\",\n",
       " \"feeling's\",\n",
       " \"felicita'\",\n",
       " \"fella's\",\n",
       " \"festi'neuch\",\n",
       " \"ff13's\",\n",
       " \"fiddler's\",\n",
       " \"filter's\",\n",
       " \"finlay's\",\n",
       " \"flippin'\",\n",
       " \"fool's\",\n",
       " \"foolin'\",\n",
       " \"forever's\",\n",
       " \"formteacher's\",\n",
       " \"fox's\",\n",
       " \"frank's\",\n",
       " \"franky's\",\n",
       " \"freakin'\",\n",
       " \"friday's\",\n",
       " \"friend's\",\n",
       " \"friendly'\",\n",
       " \"fuck'em\",\n",
       " \"fuck's\",\n",
       " \"fuckin'\",\n",
       " \"fung's\",\n",
       " \"g'boro\",\n",
       " \"g'day\",\n",
       " \"g'morning\",\n",
       " \"g'mâ\",\n",
       " \"gabriel's\",\n",
       " \"game's\",\n",
       " \"gandhi's\",\n",
       " \"gb's\",\n",
       " \"gej's\",\n",
       " \"geoffrey's\",\n",
       " \"george'squestforworldpeace\",\n",
       " \"germany's\",\n",
       " \"get's\",\n",
       " \"gettin'\",\n",
       " \"gfriend's\",\n",
       " \"gimmie'\",\n",
       " \"gingrich's\",\n",
       " \"girl's\",\n",
       " \"girls'\",\n",
       " \"givin'me\",\n",
       " \"glamours'\",\n",
       " \"glasto'\",\n",
       " \"globalfundwomen's\",\n",
       " \"globe's\",\n",
       " \"go's\",\n",
       " \"god's\",\n",
       " \"god'slove\",\n",
       " \"god'sâ\",\n",
       " \"gold's\",\n",
       " \"golinski's\",\n",
       " \"good'\",\n",
       " \"gorilla'\",\n",
       " \"gov't\",\n",
       " \"government's\",\n",
       " \"grammaw's\",\n",
       " \"granddaughter's\",\n",
       " \"grandma's\",\n",
       " \"grandmother's\",\n",
       " \"grass'\",\n",
       " \"green's\",\n",
       " \"griffith's\",\n",
       " \"grillin'\",\n",
       " \"grimmie's\",\n",
       " \"group's\",\n",
       " \"groups'\",\n",
       " \"gulliver's\",\n",
       " \"guy's\",\n",
       " \"gyal's\",\n",
       " \"h's\",\n",
       " \"hackett's\",\n",
       " \"hadn't\",\n",
       " \"hairdresser's\",\n",
       " \"halo's\",\n",
       " \"hamid's\",\n",
       " \"hands'\",\n",
       " \"hangin'\",\n",
       " \"happen'\",\n",
       " \"happyfather'sdayð\",\n",
       " \"happylion's\",\n",
       " \"harmer's\",\n",
       " \"harrisburg's\",\n",
       " \"harry's\",\n",
       " \"hashmi's\",\n",
       " \"hasn't\",\n",
       " \"hatchling's\",\n",
       " \"hater's\",\n",
       " \"haven't\",\n",
       " \"hayley's\",\n",
       " \"hc's\",\n",
       " \"hd's\",\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " \"hea's\",\n",
       " \"here'\",\n",
       " \"here's\",\n",
       " \"hero's\",\n",
       " \"herschlag's\",\n",
       " \"hill's\",\n",
       " \"hillary's\",\n",
       " \"hillaryclinton's\",\n",
       " \"hobi's\",\n",
       " \"hockey's\",\n",
       " \"home'\",\n",
       " \"hong's\",\n",
       " \"hop's\",\n",
       " \"hope's\",\n",
       " \"hopeitdoesn'train\",\n",
       " \"hoppin'\",\n",
       " \"hossein's\",\n",
       " \"host's\",\n",
       " \"how's\",\n",
       " \"howard's\",\n",
       " \"howe's\",\n",
       " \"hrc's\",\n",
       " \"humanity'\",\n",
       " \"humanity's\",\n",
       " \"hunt's\",\n",
       " \"husband's\",\n",
       " \"hv's\",\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i'ma\",\n",
       " \"i'manadultnow\",\n",
       " \"i'mbroke\",\n",
       " \"i'mdeafâ\",\n",
       " \"i'mlovingit\",\n",
       " \"i'mout\",\n",
       " \"i've\",\n",
       " \"ican'teven\",\n",
       " \"ife's\",\n",
       " \"iftar's\",\n",
       " \"igwe's\",\n",
       " \"iknowthingsuthinkidon'tknow\",\n",
       " \"imagination's\",\n",
       " \"imm'ts\",\n",
       " \"in't\",\n",
       " \"india's\",\n",
       " \"industry's\",\n",
       " \"instagram's\",\n",
       " \"int'l\",\n",
       " \"intal's\",\n",
       " \"intelligence'\",\n",
       " \"intent'\",\n",
       " \"intl'l\",\n",
       " \"ioc's\",\n",
       " \"iqbal's\",\n",
       " \"isabelle's\",\n",
       " \"isis'\",\n",
       " \"islamism'\",\n",
       " \"isn't\",\n",
       " \"israel's\",\n",
       " \"it'\",\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " \"it'sâ\",\n",
       " \"italy'\",\n",
       " \"itget'sold\",\n",
       " \"itshe's\",\n",
       " \"itwon'tspreadlikethis\",\n",
       " \"ivana's\",\n",
       " \"jack's\",\n",
       " \"jackson's\",\n",
       " \"jacqueline's\",\n",
       " \"jahn's\",\n",
       " \"james'\",\n",
       " \"james's\",\n",
       " \"jammin'\",\n",
       " \"jane's\",\n",
       " \"japan's\",\n",
       " \"jaxon's\",\n",
       " \"jazza's\",\n",
       " \"jeffree's\",\n",
       " \"jenny's\",\n",
       " \"jessica's\",\n",
       " \"jews'\",\n",
       " \"jimmy's\",\n",
       " \"jiraiya's\",\n",
       " \"jk's\",\n",
       " \"jo'\",\n",
       " \"jo's\",\n",
       " \"jock's\",\n",
       " \"jocox's\",\n",
       " \"johnson's\",\n",
       " \"joking'\",\n",
       " \"jordan's\",\n",
       " \"journal's\",\n",
       " \"journalists'\",\n",
       " \"journey'\",\n",
       " \"joy'\",\n",
       " \"jpy's\",\n",
       " \"jts88's\",\n",
       " \"judge's\",\n",
       " \"july'16\",\n",
       " \"june's\",\n",
       " \"jungkook's\",\n",
       " \"justin's\",\n",
       " \"kai's\",\n",
       " \"kaitlin's\",\n",
       " \"kanye's\",\n",
       " \"kapitbahay's\",\n",
       " \"kardashian's\",\n",
       " \"karma's\",\n",
       " \"kate's\",\n",
       " \"katee's\",\n",
       " \"katie's\",\n",
       " \"ke's\",\n",
       " \"keithellison's\",\n",
       " \"kellogg's\",\n",
       " \"keshi's\",\n",
       " \"kid's\",\n",
       " \"kilwin's\",\n",
       " \"king's\",\n",
       " \"kingdom's\",\n",
       " \"kitty's\",\n",
       " \"kkk'\",\n",
       " \"knott's\",\n",
       " \"ko's\",\n",
       " \"l'a\",\n",
       " \"l'impact\",\n",
       " \"l'italien\",\n",
       " \"l'm\",\n",
       " \"l'pool\",\n",
       " \"l's\",\n",
       " \"l'vivs\",\n",
       " \"labourin's\",\n",
       " \"lady's\",\n",
       " \"lafnwebseries's\",\n",
       " \"lamy's\",\n",
       " \"lappy's\",\n",
       " \"laptop's\",\n",
       " \"laughin'\",\n",
       " \"league's\",\n",
       " \"lee's\",\n",
       " \"left's\",\n",
       " \"leo's\",\n",
       " \"let's\",\n",
       " \"levendale's\",\n",
       " \"lg's\",\n",
       " \"lgbtq's\",\n",
       " \"lies'\",\n",
       " \"life's\",\n",
       " \"light'\",\n",
       " \"lil'\",\n",
       " \"lil'b\",\n",
       " \"lily's\",\n",
       " \"limiting'\",\n",
       " \"link's\",\n",
       " \"linkedin'sh\",\n",
       " \"lion's\",\n",
       " \"list'\",\n",
       " \"littleun's\",\n",
       " \"live's\",\n",
       " \"liverpool's\",\n",
       " \"livin'thing\",\n",
       " \"lol'd\",\n",
       " \"look's\",\n",
       " \"lookin'\",\n",
       " \"lot's\",\n",
       " \"love'\",\n",
       " \"love's\",\n",
       " \"loveca's\",\n",
       " \"lover's\",\n",
       " \"lt's\",\n",
       " \"lucky'\",\n",
       " \"lyin'\",\n",
       " \"lyin'crookedhillary\",\n",
       " \"m'am\",\n",
       " \"m's\",\n",
       " \"m'sâ\",\n",
       " \"m'y\",\n",
       " \"ma'am\",\n",
       " \"ma'ana\",\n",
       " \"ma'likrichmond\",\n",
       " \"ma'm\",\n",
       " \"ma'u\",\n",
       " \"macdonald's\",\n",
       " \"macgregor's\",\n",
       " \"madison's\",\n",
       " \"magic's\",\n",
       " \"mainez's\",\n",
       " \"make'em\",\n",
       " \"man'\",\n",
       " \"man's\",\n",
       " \"manny's\",\n",
       " \"mark's\",\n",
       " \"marx's\",\n",
       " \"mary's\",\n",
       " \"master's\",\n",
       " \"masters'\",\n",
       " \"matchup's\",\n",
       " \"mateen's\",\n",
       " \"mathew'\",\n",
       " \"max's\",\n",
       " \"mc's\",\n",
       " \"mcdonald's\",\n",
       " \"me'\",\n",
       " \"meeee'\",\n",
       " \"meeting'\",\n",
       " \"megan's\",\n",
       " \"memoriam'\",\n",
       " \"men's\",\n",
       " \"menchie's\",\n",
       " \"meng's\",\n",
       " \"mercenary's\",\n",
       " \"messiha's\",\n",
       " \"mexico's\",\n",
       " \"mf's\",\n",
       " \"michael's\",\n",
       " \"mickler's\",\n",
       " \"microsoft's\",\n",
       " \"midsummer's\",\n",
       " \"might've\",\n",
       " \"minister'\",\n",
       " \"missin'\",\n",
       " \"mistake'\",\n",
       " \"mitchy'\",\n",
       " \"mla's\",\n",
       " \"mma's\",\n",
       " \"mo'nique\",\n",
       " \"moanin'\",\n",
       " \"model's\",\n",
       " \"moe's\",\n",
       " \"molly's\",\n",
       " \"mom's\",\n",
       " \"monday's\",\n",
       " \"month's\",\n",
       " \"mornin'\",\n",
       " \"morning's\",\n",
       " \"mother's\",\n",
       " \"movie's\",\n",
       " \"mp's\",\n",
       " \"mp'â\",\n",
       " \"ms's\",\n",
       " \"much'\",\n",
       " \"mum's\",\n",
       " \"muppet's\",\n",
       " \"murderer's\",\n",
       " \"muslim's\",\n",
       " \"myanmar's\",\n",
       " \"n'\",\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apostrophe_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f9ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21945895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dict(text, dictionary):\n",
    "    words = [dictionary[word] if word in list(dictionary.keys()) else word for word in text.split()]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b67f5c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   welcome here !  i'm   it's so #gr8 ! \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a72880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(replace_dict)(df.tweet, apostrophe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72606d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here ! I am it has / it is so #gr8 !'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe44fa",
   "metadata": {},
   "source": [
    "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2c5a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7276b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ap(text):\n",
    "    words = re.sub('#','', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "282cb63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(find_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "082276f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here ! I am it has / it is so gr8 !'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6019e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(replace_dict)(df.tweet, short_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc5b1c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here ! I am it has / it is so great !'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2bde94",
   "metadata": {},
   "source": [
    "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aa4c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "619a62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(replace_dict)(df.tweet, emoticon_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfea611",
   "metadata": {},
   "source": [
    "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
    "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
    "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba711f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here ! I am it has / it is so great !'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eee0e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_punctuation(pattern, repl, string):\n",
    "    return re.sub(pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4fbd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(del_punctuation)(r'[^\\w\\s]', ' ', df.tweet)\n",
    "df.tweet = np.vectorize(del_punctuation)(r'[^a-zA-Z0-9]', ' ', df.tweet)\n",
    "df.tweet = np.vectorize(del_punctuation)(r'[^a-zA-Z]', ' ', df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2507647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here   I am it has   it is so great  '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694a8c2",
   "metadata": {},
   "source": [
    "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5d853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_len(text):\n",
    "    return ' '.join([w for w in text.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37c1cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet = np.vectorize(del_len)(df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9581516d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome here am it has it is so great'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b6da5",
   "metadata": {},
   "source": [
    "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0afd73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9422343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_token']=df.tweet.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ea6144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, is, dysfunctional, and, is, so,...\n",
       "1    [thanks, for, lyft, credit, can, not, use, cau...\n",
       "2                              [bihday, your, majesty]\n",
       "3    [model, love, you, take, with, you, all, the, ...\n",
       "4               [factsguide, society, now, motivation]\n",
       "Name: tweet_token, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_token'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e0385",
   "metadata": {},
   "source": [
    "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20b974f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efc6306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80cc001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(tokens, stop_words=stop_words):\n",
    "    return [w for w in tokens if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9425ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_token_filtered']= df.tweet_token.apply(delete_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d920f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [father, dysfunctional, selfish, drags, kids, ...\n",
       "1        [thanks, lyft, credit, use, cause, offer, whee...\n",
       "2                                        [bihday, majesty]\n",
       "3                            [model, love, take, time, ur]\n",
       "4                        [factsguide, society, motivation]\n",
       "                               ...                        \n",
       "49154    [thought, factory, left, right, polarisation, ...\n",
       "49155    [feeling, like, mermaid, hairflip, neverready,...\n",
       "49156    [hillary, campaigned, today, ohio, omg, amp, u...\n",
       "49157    [happy, work, conference, right, mindset, lead...\n",
       "49158    [song, glad, free, download, shoegaze, newmusi...\n",
       "Name: tweet_token_filtered, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_token_filtered']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f58f24",
   "metadata": {},
   "source": [
    "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e38aed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [father, dysfunct, selfish, drag, kid, dysfunc...\n",
       "1        [thank, lyft, credit, use, caus, offer, wheelc...\n",
       "2                                        [bihday, majesti]\n",
       "3                            [model, love, take, time, ur]\n",
       "4                              [factsguid, societi, motiv]\n",
       "                               ...                        \n",
       "49154    [thought, factori, left, right, polaris, trump...\n",
       "49155    [feel, like, mermaid, hairflip, neverreadi, fo...\n",
       "49156    [hillari, campaign, today, ohio, omg, amp, use...\n",
       "49157    [happi, work, confer, right, mindset, lead, cu...\n",
       "49158    [song, glad, free, download, shoegaz, newmus, ...\n",
       "Name: tweet_stemmed, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def steming_tokens(tokens):\n",
    "    return [stemmer.stem(w) for w in tokens]\n",
    "\n",
    "df['tweet_stemmed'] = df.tweet_token_filtered.apply(steming_tokens)\n",
    "df.tweet_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252bb18",
   "metadata": {},
   "source": [
    "13. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e200e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/recpi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [father, dysfunctional, selfish, drag, kid, dy...\n",
       "1        [thanks, lyft, credit, use, cause, offer, whee...\n",
       "2                                        [bihday, majesty]\n",
       "3                            [model, love, take, time, ur]\n",
       "4                        [factsguide, society, motivation]\n",
       "                               ...                        \n",
       "49154    [thought, factory, left, right, polarisation, ...\n",
       "49155    [feeling, like, mermaid, hairflip, neverready,...\n",
       "49156    [hillary, campaigned, today, ohio, omg, amp, u...\n",
       "49157    [happy, work, conference, right, mindset, lead...\n",
       "49158    [song, glad, free, download, shoegaze, newmusi...\n",
       "Name: tweet_lemmatized, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatized_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "df['tweet_lemmatized'] = df.tweet_token_filtered.apply(lemmatized_tokens)\n",
    "df.tweet_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ff246",
   "metadata": {},
   "source": [
    "14. Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a69b73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40147</th>\n",
       "      <td>40148</td>\n",
       "      <td>if say there has there is abuse or or anything...</td>\n",
       "      <td>[if, say, there, has, there, is, abuse, or, or...</td>\n",
       "      <td>[say, abuse, anything, like, take]</td>\n",
       "      <td>[say, abus, anyth, like, take]</td>\n",
       "      <td>[say, abuse, anything, like, take]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "40147  40148  if say there has there is abuse or or anything...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "40147  [if, say, there, has, there, is, abuse, or, or...   \n",
       "\n",
       "                     tweet_token_filtered                   tweet_stemmed  \\\n",
       "40147  [say, abuse, anything, like, take]  [say, abus, anyth, like, take]   \n",
       "\n",
       "                         tweet_lemmatized  \n",
       "40147  [say, abuse, anything, like, take]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7d49291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Practice_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbccae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
