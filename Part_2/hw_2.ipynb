{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тема “Создание признакового пространства”\n",
    "---\n",
    "\n",
    "Продолжим обработку данных с Твиттера. \n",
    "\n",
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    " - Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    " - Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    " - Исключим стоп-слова с помощью stop_words='english'. \n",
    " - Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n",
    " \n",
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    " - Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    " - Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    " - Исключим стоп-слова с помощью stop_words='english'.\n",
    " - Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n",
    "\n",
    "\n",
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:27.318157Z",
     "start_time": "2021-07-06T21:59:25.902107Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:27.663955Z",
     "start_time": "2021-07-06T21:59:27.318157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit can use cause they don ...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, use, cause, t...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit can use cause they don ...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, use, cause, t...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.read_pickle(\"../../data/nlp/tweets.pkl\")\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:27.743036Z",
     "start_time": "2021-07-06T21:59:27.668918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit can use cause they don ...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, use, cause, t...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>model love take time ur</td>\n",
       "      <td>model love take time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguid societi motiv</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit can use cause they don ...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, use, cause, t...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0      father dysfunct selfish drag kid dysfunct run   \n",
       "1  thank lyft credit use caus offer wheelchair va...   \n",
       "2                                     bihday majesti   \n",
       "3                            model love take time ur   \n",
       "4                            factsguid societi motiv   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thanks lyft credit use cause offer wheelchair ...  \n",
       "2                                     bihday majesty  \n",
       "3                            model love take time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем данные и выделим их в отдельный датафрейм\n",
    "combine_df['tweet_stemmed'] = combine_df['tweet_stemmed'].apply(lambda tokens: ' '.join(tokens))\n",
    "combine_df['tweet_lemmatized'] = combine_df['tweet_lemmatized'].apply(lambda tokens: ' '.join(tokens))\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью `sklearn.feature_extraction.text.CountVectorizer.fit_transform()`. Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью `max_df`.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью `max_features = 1000`.\n",
    "- Исключим стоп-слова с помощью `stop_words='english'`. \n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью `CountVectorizer.get_feature_names()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:27.759031Z",
     "start_time": "2021-07-06T21:59:27.744993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, max_features=1000, stop_words='english',\n",
       "                tokenizer=<method 'split' of 'str' objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   tokenizer=str.split, # процедура токенизации\n",
    "                                   stop_words=\"english\", \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=1000)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:28.153277Z",
     "start_time": "2021-07-06T21:59:27.761998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49159x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 206686 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель для tweet_stemmed\n",
    "bag_of_words_stemmed = count_vectorizer.fit_transform(combine_df['tweet_stemmed'])\n",
    "bag_of_words_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:28.247524Z",
     "start_time": "2021-07-06T21:59:28.155278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual  ad  adapt  ...  \\\n",
       "0    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "1    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "2    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "3    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "4    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "columns = count_vectorizer.get_feature_names()\n",
    "stemmed_count = pd.DataFrame(bag_of_words_stemmed.toarray(), columns=columns)\n",
    "stemmed_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:28.660571Z",
     "start_time": "2021-07-06T21:59:28.250493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49159x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 191317 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель для tweet_lemmatized\n",
    "bag_of_words_lemmatized = count_vectorizer.fit_transform(combine_df['tweet_lemmatized'])\n",
    "bag_of_words_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:28.753602Z",
     "start_time": "2021-07-06T21:59:28.662532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "0     0           0        0    0       0      0         0      0    0   \n",
       "1     0           0        0    0       0      0         0      0    0   \n",
       "2     0           0        0    0       0      0         0      0    0   \n",
       "3     0           0        0    0       0      0         0      0    0   \n",
       "4     0           0        0    0       0      0         0      0    0   \n",
       "\n",
       "   adventure  ...  year  yes  yesterday  yo  yoga  york  young  youtube  yr  \\\n",
       "0          0  ...     0    0          0   0     0     0      0        0   0   \n",
       "1          0  ...     0    0          0   0     0     0      0        0   0   \n",
       "2          0  ...     0    0          0   0     0     0      0        0   0   \n",
       "3          0  ...     0    0          0   0     0     0      0        0   0   \n",
       "4          0  ...     0    0          0   0     0     0      0        0   0   \n",
       "\n",
       "   yummy  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "columns = count_vectorizer.get_feature_names()\n",
    "lemmatized_count = pd.DataFrame(bag_of_words_lemmatized.toarray(), columns=columns)\n",
    "lemmatized_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью `sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью `max_df`.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью `max_features = 1000`.\n",
    "- Исключим стоп-слова с помощью `stop_words='english'`.\n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью `TfidfVectorizer.get_feature_names()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:28.769563Z",
     "start_time": "2021-07-06T21:59:28.755565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english',\n",
       "                tokenizer=<method 'split' of 'str' objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   tokenizer=str.split, \n",
    "                                   stop_words='english', \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=1000)\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.151721Z",
     "start_time": "2021-07-06T21:59:28.771566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49159x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 206686 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель для tweet_stemmed\n",
    "bag_of_words_stemmed = tfidf_vectorizer.fit_transform(combine_df['tweet_stemmed'])\n",
    "bag_of_words_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.245974Z",
     "start_time": "2021-07-06T21:59:29.153680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual   ad  adapt  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "3  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "4  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "3   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "4   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "columns = tfidf_vectorizer.get_feature_names()\n",
    "stemmed_tfidf = pd.DataFrame(bag_of_words_stemmed.toarray(), columns=columns)\n",
    "stemmed_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.645974Z",
     "start_time": "2021-07-06T21:59:29.247950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Создаем the Bag-of-Words модель для tweet_lemmatized\n",
    "bag_of_words_lemmatized = tfidf_vectorizer.fit_transform(combine_df['tweet_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.738976Z",
     "start_time": "2021-07-06T21:59:29.646974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "0   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "1   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "2   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "3   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "4   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "\n",
       "   adventure  ...  year  yes  yesterday   yo  yoga  york  young  youtube   yr  \\\n",
       "0        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "1        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "2        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "3        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "4        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "\n",
       "   yummy  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "columns = tfidf_vectorizer.get_feature_names()\n",
    "lemmatized_tfidf = pd.DataFrame(bag_of_words_lemmatized.toarray(), columns=columns)\n",
    "lemmatized_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, \n",
    "- составьте таблицу метод векторизации и скор который вы получили (в методах векторизации поизменяйте параметры что бы добиться лучшего скора)\n",
    "- обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, \n",
    "- попробуйте применить к векторайзерам PCA для сокращения размерности. Посмотрите на качество сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.831953Z",
     "start_time": "2021-07-06T21:59:29.740973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:29.847952Z",
     "start_time": "2021-07-06T21:59:29.832965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__label__2', '__label__1'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:32.817188Z",
     "start_time": "2021-07-06T21:59:29.849955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:01<00:02,  1.35s/it]C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:02<00:01,  1.20s/it]C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_vect</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.430207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_vectorizer</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.314968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_vectorizer</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.332574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vectorizer     mse     mae  r2 score\n",
       "0        count_vect  0.1424  0.1424  0.430207\n",
       "1  count_vectorizer  0.1712  0.1712  0.314968\n",
       "2  tfidf_vectorizer  0.1668  0.1668  0.332574"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаём векторайзеры\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   tokenizer=str.split, # процедура токенизации\n",
    "                                   stop_words=\"english\", \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=12000)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   tokenizer=str.split, \n",
    "                                   stop_words='english', \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=8000)\n",
    "\n",
    "# список векторайзеров\n",
    "vectorizers = [['count_vect', count_vect], ['count_vectorizer', count_vectorizer], ['tfidf_vectorizer', tfidf_vectorizer]]\n",
    "\n",
    "# пустой датафрейм для записи результатов\n",
    "results = pd.DataFrame(columns=['vectorizer', 'mse', 'mae', 'r2 score'])\n",
    "\n",
    "i = 0\n",
    "for vectorizer in tqdm(vectorizers):\n",
    "    train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'],\n",
    "                                                                          trainDF['label'],\n",
    "                                                                          train_size=0.75, \n",
    "                                                                          shuffle=False, \n",
    "                                                                          random_state=1,\n",
    "                                                                         )\n",
    "    # labelEncode целевую переменную\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    train_y = encoder.fit_transform(train_y)\n",
    "    valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "\n",
    "    vectorizer[1].fit(trainDF['text'])\n",
    "\n",
    "    xtrain_count =  vectorizer[1].transform(train_x)\n",
    "    xvalid_count =  vectorizer[1].transform(valid_x)\n",
    "\n",
    "    #classifier = linear_model.LogisticRegression() # без указания солвера ошибка: 'str' object has no attribute 'decode'\n",
    "    classifier = linear_model.LogisticRegression(solver='liblinear')\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    #accuracy_score(valid_y, predictions)\n",
    "    results.loc[i] = [vectorizer[0], \n",
    "                    mean_squared_error(valid_y, predictions), \n",
    "                    mean_absolute_error(valid_y, predictions),\n",
    "                    r2_score(valid_y, predictions)\n",
    "                     ]\n",
    "    i += 1\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: максимальное качество при количестве слов векторайзеров 12000 для countVectorizer и 8000 для TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:35.783877Z",
     "start_time": "2021-07-06T21:59:32.819180Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_vectorizer</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.332574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vectorizer     mse     mae  r2 score\n",
       "1  tfidf_vectorizer  0.1668  0.1668  0.332574"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаём векторайзер\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   tokenizer=str.split, \n",
    "                                   stop_words='english', \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=8000)\n",
    "\n",
    "# пустой датафрейм для записи результатов\n",
    "results = pd.DataFrame(columns=['vectorizer', 'mse', 'mae', 'r2 score'])\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(lemmatized_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'],\n",
    "                                                                      trainDF['label'],\n",
    "                                                                      train_size=0.75, \n",
    "                                                                      shuffle=False, \n",
    "                                                                      random_state=1,\n",
    "                                                                     )\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "\n",
    "vectorizer[1].fit(trainDF['text'])\n",
    "\n",
    "xtrain_count =  vectorizer[1].transform(train_x)\n",
    "xvalid_count =  vectorizer[1].transform(valid_x)\n",
    "\n",
    "#classifier = linear_model.LogisticRegression() # без указания солвера ошибка: 'str' object has no attribute 'decode'\n",
    "classifier = linear_model.LogisticRegression(solver='liblinear')\n",
    "classifier.fit(xtrain_count, train_y)\n",
    "predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "#accuracy_score(valid_y, predictions)\n",
    "results.loc[1] = [vectorizer[0], \n",
    "                mean_squared_error(valid_y, predictions), \n",
    "                mean_absolute_error(valid_y, predictions),\n",
    "                r2_score(valid_y, predictions)\n",
    "                 ]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:48.759151Z",
     "start_time": "2021-07-06T21:59:35.785880Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.055680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.094093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.126104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.159716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.214134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.242944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.255748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1700.0</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.271753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.289359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.332574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4400.0</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.324571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5900.0</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.335775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8100.0</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.332574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.322971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.338976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_features     mse     mae  r2 score\n",
       "0        200.0  0.2360  0.2360  0.055680\n",
       "1        300.0  0.2264  0.2264  0.094093\n",
       "2        400.0  0.2184  0.2184  0.126104\n",
       "3        500.0  0.2100  0.2100  0.159716\n",
       "4        700.0  0.1964  0.1964  0.214134\n",
       "5        900.0  0.1892  0.1892  0.242944\n",
       "6       1300.0  0.1860  0.1860  0.255748\n",
       "7       1700.0  0.1820  0.1820  0.271753\n",
       "8       2400.0  0.1776  0.1776  0.289359\n",
       "9       3200.0  0.1668  0.1668  0.332574\n",
       "10      4400.0  0.1688  0.1688  0.324571\n",
       "11      5900.0  0.1660  0.1660  0.335775\n",
       "12      8100.0  0.1668  0.1668  0.332574\n",
       "13     11000.0  0.1692  0.1692  0.322971\n",
       "14     15000.0  0.1652  0.1652  0.338976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пустой датафрейм для записи результатов\n",
    "results = pd.DataFrame(columns=['n_features', 'mse', 'mae', 'r2 score'])\n",
    "\n",
    "i = 0\n",
    "for n_features in np.geomspace(200, 15000, 15).round(-2):\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                                       analyzer='word', \n",
    "                                       binary=False, \n",
    "                                       tokenizer=str.split, \n",
    "                                       stop_words='english', \n",
    "                                       max_df=0.9, \n",
    "                                       max_features=int(n_features))\n",
    "    \n",
    "    train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'],\n",
    "                                                                          trainDF['label'],\n",
    "                                                                          train_size=0.75, \n",
    "                                                                          shuffle=False, \n",
    "                                                                          random_state=1,\n",
    "                                                                         )\n",
    "    # labelEncode целевую переменную\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    train_y = encoder.fit_transform(train_y)\n",
    "    valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "\n",
    "    tfidf_vectorizer.fit(trainDF['text'])\n",
    "\n",
    "    xtrain_count =  tfidf_vectorizer.transform(train_x)\n",
    "    xvalid_count =  tfidf_vectorizer.transform(valid_x)\n",
    "\n",
    "    #classifier = linear_model.LogisticRegression() # без указания солвера ошибка: 'str' object has no attribute 'decode'\n",
    "    classifier = linear_model.LogisticRegression(solver='liblinear')\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    #accuracy_score(valid_y, predictions)\n",
    "    results.loc[i] = [n_features, \n",
    "                    mean_squared_error(valid_y, predictions), \n",
    "                    mean_absolute_error(valid_y, predictions),\n",
    "                    r2_score(valid_y, predictions)\n",
    "                     ]\n",
    "    i += 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T21:59:48.965704Z",
     "start_time": "2021-07-06T21:59:48.761155Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['n_features'], results['r2 score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: количество фичей в районе 5000 достаточно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T22:03:59.619641Z",
     "start_time": "2021-07-06T22:02:34.645169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pca</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.042144</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>0.020949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.087218</td>\n",
       "      <td>0.024080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.089695</td>\n",
       "      <td>0.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.090636</td>\n",
       "      <td>0.038329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.040464</td>\n",
       "      <td>0.091775</td>\n",
       "      <td>0.061570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.089721</td>\n",
       "      <td>0.066121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.087837</td>\n",
       "      <td>0.095025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.085232</td>\n",
       "      <td>0.118937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>0.083693</td>\n",
       "      <td>0.159889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.038257</td>\n",
       "      <td>0.086276</td>\n",
       "      <td>0.123298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>0.083222</td>\n",
       "      <td>0.197451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>340.0</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.080590</td>\n",
       "      <td>0.191249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>470.0</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.203921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>650.0</td>\n",
       "      <td>0.034567</td>\n",
       "      <td>0.080771</td>\n",
       "      <td>0.198338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.034411</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_pca       mse       mae  r2 score\n",
       "0    10.0  0.042144  0.087792  0.020949\n",
       "1    10.0  0.042225  0.087218  0.024080\n",
       "2    20.0  0.045192  0.089695  0.023717\n",
       "3    30.0  0.041395  0.090636  0.038329\n",
       "4    40.0  0.040464  0.091775  0.061570\n",
       "5    50.0  0.042061  0.089721  0.066121\n",
       "6    70.0  0.040493  0.087837  0.095025\n",
       "7    90.0  0.036946  0.085232  0.118937\n",
       "8   130.0  0.036784  0.083693  0.159889\n",
       "9   180.0  0.038257  0.086276  0.123298\n",
       "10  250.0  0.036205  0.083222  0.197451\n",
       "11  340.0  0.034573  0.080590  0.191249\n",
       "12  470.0  0.035561  0.081461  0.203921\n",
       "13  650.0  0.034567  0.080771  0.198338\n",
       "14  900.0  0.034411  0.082414  0.208741"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменяем пропуски нулями\n",
    "combine_df['label'] = combine_df['label'].apply(lambda y: 0 if np.isnan(y) else y)\n",
    "y = combine_df['label'].astype('float32')\n",
    "\n",
    "# пустой датафрейм для записи результатов\n",
    "results = pd.DataFrame(columns=['n_pca', 'mse', 'mae', 'r2 score'])\n",
    "\n",
    "i = 0\n",
    "for n_pca in np.geomspace(10, 900, 15).round(-1):\n",
    "    pca = decomposition.PCA(n_components=int(n_pca))\n",
    "    pca.fit(lemmatized_tfidf)\n",
    "\n",
    "    X_lemmatized_tfidf_pca = pca.transform(lemmatized_tfidf)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_lemmatized_tfidf_pca, y)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.loc[i] = [n_pca, \n",
    "                mean_squared_error(y_test, y_pred), \n",
    "                mean_absolute_error(y_test, y_pred),\n",
    "                r2_score(y_test, y_pred)\n",
    "                 ]\n",
    "    i += 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T22:07:06.045781Z",
     "start_time": "2021-07-06T22:07:05.945725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmMUlEQVR4nO3de3BcZ5nn8e+jq3WxrYsl3yTfjR1nkjhG69yBxAlJ2BkMNcNUYCaThVAhW8kCO8POZKa2tqiaf7IsDLNUZZIKJFthyJANAywu1otjm0CcAYMvcS6SYltxLEu21LpYsiTLuj/7Rx85bbktteSWWurz+1Spus97bm+fxOc55znv+x5zd0REJHwyUl0BERFJDQUAEZGQUgAQEQkpBQARkZBSABARCamsVFdgMhYtWuSrVq1KdTVEROaUQ4cOtbl72djyORUAVq1axcGDB1NdDRGROcXM6uOVKwUkIhJSCgAiIiGlACAiElIKACIiIaUAICISUgoAIiIhpQAgIhJSc6ofgIhIGAwNj9B0ro+Gjl4az16goaOXP62qpLIkP6n7UQAQEZlhIyNOa08/DWd7LznJNwSfTef6GB754F0tGQZbVhQrAIiIzHbuTkfvIA1ne2nsGD2599LQcYHGs700dl5gYGjkknXK5+dSWZJP1cpiKorzqSzJo7I4n8qSfJYsnEd2ZvIz9goAIiJT0N03GD25Byf26Mm+92LZ+YHhS5Yvzs+msiSfjUvnc8+mxVSU5FNZnEdlST7Li/KYl505479BAUBEJI6+weGLV++No1fvMWmazt7BS5YvyMmksiSfiuJ8bllbSmVxPhXBCb6iOI/587JT9EuuTAFAJMncnaORbg7VdzB/Xjbl83Mpm59L+fxcCnOzMLNUV1GAweERmjr7LqZnxqZqWrv7L1k+JysjekIvzuf6ioVUluQHKZpoWVF+9pz7b6sAIJIE/UPD7D9xlr21EfbWtnC680Lc5eZlZ1A+f97FgFA2P5eywlzKF4wGiei80oIcsqYh5xsmIyNOpLuPhrOXXrmPnuybzl0g5jkrmRnGsqJ5VBTlc+eGsov599Gr+LLCXDIy5tYJfiIJBQAzuw/4n0Am8D13f3LM/D8D/iaY7AH+o7u/Od66ZlYC/G9gFXAS+FN377jK3yMyY9p6+nn13Rb21raw73gr5weGmZedwe3rFvH4Xeu4be0i+oaGae3up6W7L/rZ1U9rT/TzeEsPv3mvnXMXBi/bthmUFuSwqDCX8gXzPggSl3xGg0VBTuacu/JMBnen/fxATB6+9+LJvrHjAqc7LjAwfOmD1sULcqkszmfr6hIqi/OoKM6nIriCX7pwXuiCrrn7+AuYZQLHgHuARuAA8Fl3r4lZ5lag1t07zOx+4OvuftN465rZN4Cz7v6kmT0BFLv73zCOqqoq1/sAJFVGUzt7a1vYUxvhSEMn7rBkwTzuuqacu68p59a1iyb9MK9vcJi2nn5auvuDYBH9jP71XVI2NHL5v9e87Mz4waEwuMMI7jZKC3PJnGNXsF190ZY0H1zFf5Cqaey4QO+YB60lBTmXndgrg4ety1L0oHU2MLND7l41tjyRO4CtQJ27nwg29BKwHbgYANz9NzHL7wcqElh3O/CxYLkXgF/xwV2EyKwwmtr5ZW2EPTGpnesrFvKVbeu5+5rFXLtswVVdgc/LzoyesIrHb+M9MuJ0Xhi85I4iNji0dPdxtLmbfd1tdPcNXbZ+hkFJQUzqKSYNNTYtVZA7M9nhCwPD0RN7TOuZ2FRN15jfUZibRUVxHitLC7h9XRmVJXkXm0xWFOdTOEP1TheJHK3lQEPMdCNw0zjLPwz8vwTWXezuTQDu3mRm5fE2ZmaPAI8ArFixIoHqilydiVI7d20sZ/GCeTNer4wMo6Qgh5KCHDYsmT/usn2Dw2PuJvrGBIt+jjZ309YT/64iPyfzsuAwNmhEn1WMf1cxMDTCmc4Llz1gHb2Sb+u59EFr7uiD1pJ8blxRFHMFHz3JL8ybew9aZ7NEAkC8ox03b2RmdxINALdPdt0rcfdngWchmgKazLoiiRgvtbP9xuVTTu2k0rzsaJPEiXqOjow4Hb0DF59LjL2jaO3up7api9eO9dPdH/+uorQw95KWTkMjTmPQ4am5q++SB61ZGcayojwqivPYtrE82oJm9EFrcT6L0vBB62yWSABoBCpjpiuAM2MXMrPrge8B97t7ewLrRsxsaXD1vxRomWzlZWbVNnXxo4ONXLN0PjeuKGLNosI5+491JlI7c0FGhlFaGH0+sHHJ+MteGIjeVbT29F3yMDtaFg0YNWe6yDCjsiSPm9eUUhFzcq8syWPJgvA9aJ3NEgkAB4D1ZrYaOA08AHwudgEzWwH8BHjQ3Y8luO4O4CHgyeDzZ1fxO2QGPPVqHT9/q+ni9PzcLK6rWMjmyiJuqCxic2VRSlIjiZqtqZ25Ii8nkxWl+awoTe54NJI6EwYAdx8ys8eBXUSbcj7v7tVm9mgw/xngvwGlwD8FV0xD7l51pXWDTT8JvGxmDwOngM8k+bdJEg0MjfDro638aVUFj3xkDUcaznGkoYM3G87x7GsnLuaRlyyYdzEg3FC5kOsrilL2YC42tbO3NsIbaZDaEUmmCZuBziZqBpo6+4638uBzv+e5h6rYds3iS+b1DQ5T09TFkVOdvNnYyZsNnZxs7wWi7dnXlxdyQ8UHdwkblsyfloGtYPzUzl0by0OT2hGJdTXNQEXYXRMhLzuT29YtumzevOxMtqwoZsuK4otlHecHgmAQvVPY+24LPzrUCERbevzB8pjUUUURlSV5Uz4pK7UjMjUKADIhd2dPTYQ71ieeLikuyOFjG8r52Ibyi9to7LjAGw3RO4Q3Gzr5wf56nnv9fSDageeGioVB6igaFIoLcq5Yn3ipncULctl+43K2bSzntnVK7YhMRAFAJlR9posz5/r46j0fmvI2zOxis8RP3rAMiA7GdbS5+2La6EhDJ7861spoVnJlaT43VBRdvFM43z8UHWvn3RYaO6KpneuWh6vVjkgyKQDIhPbURjCDbRvj9tWbsuzMaCroD5Yv5M9uWglAT/8Qbzee40hwl3Dg5Fl2vPlBq+PR1M5jdyq1I3K1FABkQrtrInx4RTGlhbnTvq/C3CxuWVvKLWtLL5ZFuvo40tBJTmYGt6wtVWpHJEkUAGRcpzsvUH2mi7+9f2PK6rB4wTzuvXaCXkoiMmnqkifj2lsbAeDuTYsnWFJE5hoFABnX7poIa8oKWFtWmOqqiEiSKQDIFXX1DbL/RDv3XKOrf5F0pAAgV/Tro60MDjv3KP0jkpYUAOSK9tRGKC3I4caYHr4ikj4UACSuweERXn23hbs2ls+51wiKSGIUACSuA++fpatvSK1/RNKYAoDE9UpNhNysDO5Yf/ngbyKSHhQA5DLuzp7aCLevW0R+jvoKiqQrBQC5zLvN3TR2XFDrH5E0pwAgl9lTEx387a5rkjv4m4jMLgoAcpndtRE2VxZRPl8jbYqks4QCgJndZ2ZHzazOzJ6IM3+jmf3WzPrN7Gsx5RvM7EjMX5eZfTWY93UzOx0z7xNJ+1UyZc3n+nir8Rx3q/evSNqb8AmfmWUCTwH3AI3AATPb4e41MYudBb4MfCp2XXc/CmyO2c5p4Kcxi3zb3b95FfWXJNsTDP72ceX/RdJeIncAW4E6dz/h7gPAS8D22AXcvcXdDwCD42xnG/Ceu9dPubYy7fbURlhZms+6cg3+JpLuEgkAy4GGmOnGoGyyHgB+OKbscTN7y8yeN7O44w2Y2SNmdtDMDra2tk5ht5Konv4hflMXHfxNr1YUSX+JBIB4ZwKfzE7MLAf4JPCjmOKngbVEU0RNwLfirevuz7p7lbtXlZWVTWa3Mkn7jrUyMDyi3r8iIZFIAGgEKmOmK4AzV1j2Su4HDrt7ZLTA3SPuPuzuI8B3iaaaJIV210Qoys+maqUGfxMJg0QCwAFgvZmtDq7kHwB2THI/n2VM+sfMlsZMfhp4Z5LblCQaGh7hl0dbuGtDOVmZah0sEgYTtgJy9yEzexzYBWQCz7t7tZk9Gsx/xsyWAAeBBcBI0NRzk7t3mVk+0RZEXxqz6W+Y2Wai6aSTcebLDDpY30Fn76B6/4qESEIDvbj7TmDnmLJnYr43E00NxVu3FyiNU/7gpGoq02pPTYSczAzu+JCes4iEhe71BXdnd22EW9eVUpirwd9EwkIBQKhr6aG+vVe9f0VCRgFAeKUm2jhLAUAkXBQAhD21Ea6vWMiShRr8TSRMFABCrqW7jyMNndyjq3+R0FEACLlf1rbgjnr/ioSQAkDI7a6JUFGcx8Yl81NdFRGZYQoAIdY7MMTrdW3crcHfREJJAWCWcHeGhkdmdJ/7jrfRPzSisf9FQkoBYJb4p1+9x0f/x6/oGxyesX3uromwYF4W/251yYztU0RmDwWAWcDd+fGhRk53XuCnb5yekX0Ojzi/fLeFOzeWk63B30RCSf/yZ4G6lh5OtJ0nM8N47vX3GRmZ1OsWpuTwqQ7Onh9Q5y+REFMAmAV+8U4zAH997wbqWnr49fHpf/PZnpoI2ZnGRzdo8DeRsFIAmAV21TRz44oiPn/bahYvyOX519+f9n3urolw85pSFszLnvZ9icjspACQYo0dvbxzuot7r11CTlYGD926in3H23i3uWva9vleazTlpLH/RcJNASDFXqmODsR277VLAPjc1hXkZWfy3L7puwvYHQz+tk35f5FQUwBIsV9UN7Nh8XxWLyoAoCg/hz/5cAU/O3KG1u7+adnnnpoI1y5bwPKivGnZvojMDQkFADO7z8yOmlmdmT0RZ/5GM/utmfWb2dfGzDtpZm+b2REzOxhTXmJmu83sePAZujeRt/f0c/DkWe699tIr8c/ftorBkRH+eX990vfZ1tPPoVMdav0jIhMHADPLBJ4C7gc2AZ81s01jFjsLfBn45hU2c6e7b3b3qpiyJ4C97r4e2BtMh8qe2ggjDh8P0j+j1pQVsm1jOS/ur096x7Bfvhsd/E35fxFJ5A5gK1Dn7ifcfQB4Cdgeu4C7t7j7AWBwEvveDrwQfH8B+NQk1k0Lu6qjA7Fdu2zBZfMevn0N7ecH+D9J7hi2uybCsoXz4u5TRMIlkQCwHGiImW4MyhLlwCtmdsjMHokpX+zuTQDBZ3m8lc3sETM7aGYHW1unv338TOnuG+T1423ce+2SuAOx3bymhGuXLeC519/HPTkdw/oGh9l3vJW7N2nwNxFJLADEO1NM5ox0m7tvIZpCeszMPjKJdXH3Z929yt2rysrSp9PSr462MjA8crH1z1hmxsO3r+Z4Sw+vHW9Lyj5fP95G3+CI8v8iAiQWABqBypjpCuBMojtw9zPBZwvwU6IpJYCImS0FCD5bEt1mOthV3UxpQQ4fXnnlZ99/eP0yyufn8r19J5Kyzz21EQpzs7h5TWlSticic1siAeAAsN7MVptZDvAAsCORjZtZgZnNH/0OfBx4J5i9A3go+P4Q8LPJVHwu6xsc5tV3W/j4tYvJzLhyKia2Y9jR5u6r2ufIiLOntoWPbigjJ0utf0UkgQDg7kPA48AuoBZ42d2rzexRM3sUwMyWmFkj8JfAfzWzRjNbACwGXjezN4HfA//X3X8RbPpJ4B4zOw7cE0yHwm/ea+P8wPBlrX/i+bObVjAvO+Oqh4c40thJW0+/xv4XkYuyElnI3XcCO8eUPRPzvZloamisLuCGK2yzHdiWcE3TyK53oqmYW9dOnIoZ7Rj28sFGvnbvBsrm505pn7trImRmGB/7UNxn7SISQsoFzLDhEWdPbYQ7N5aTm5WZ0DpfuG01A0Mj/OAqOobtqYlw0+oSFuZr8DcRiVIAmGEHT56l/fwA9yWQ/hk12jHsB1PsGHay7TzHW3rU+kdELqEAMMN2VUfIycrgY5Mch//hO1bTfn6Anx2ZfMewPbXRwd/U+1dEYikAzCB3Z1d1M3esW0RBbkKPXy66ZU0pm5ZOrWPYKzURNi6ZT2VJ/qTWE5H0pgAwg6rPdHG688IVO3+NZ7Rj2LFID/sm0TGs4/wAB0+e1dW/iFxGAWAG7apuJsPg7imejP/ohqBj2CSahP7y3RZGHOX/ReQyCgAzaFd1M1tXl1BSkDOl9Uc7hr12rJVjkcQ6hu2pjbB4QS7XLV84pX2KSPpSAJghJ1p7OBbpmVL6J9bntibeMaxvcJhfH2tl2zWLyRinx7GIhJMCwAzZFbz6MZHev+MpLsjhj7dU8JM3TtPWM/4bw357op3egWHl/0UkLgWAGbKrupnrKxYm5TWMX7g92jHsxf2nxl1ud02E/JxMbtHgbyIShwLADGg+18eRhs6rTv+MWltWyF0by/nn/Sev2DFsZMTZWxvhox8qY152Yj2ORSRcFABmwCs1zQCXvfv3anzx9tW09Qyw40j8kbnfPn2OSFe/Wv+IyBUpAMyAXdXNrCkrYF35/KRt85a1pVwzTsew3TURMgzu2qjB30QkPgWAadbZO8D+E2cnNfZPIkY7hh2NdPN63eUdw/bURqhaVULxFJucikj6UwCYZntrWxge8aTl/2P90Q1LKZufy/f2XdoktOFsL+82d2vsfxEZlwLANPtFdTNLF87j+orkd8TKzcrkoVtW8utjrRyP6Ri2uyba5FT5fxEZjwLANOodGOK1Y618fNNizKanI9bnblpJblYGz//bB3cBu2sirC8vZNWigmnZp4ikh4QCgJndZ2ZHzazOzJ6IM3+jmf3WzPrN7Gsx5ZVm9qqZ1ZpZtZl9JWbe183stJkdCf4+kZyfNHu8dqyV/qER7v2D5Kd/RpUU5PDHH67gx4dP097Tz7neQX5/8uyUxxsSkfCYMACYWSbwFHA/sAn4rJltGrPYWeDLwDfHlA8Bf+Xu1wA3A4+NWffb7r45+NtJmtlVHaE4P5utq0qmdT+jbwx78XenePVo9JmDev+KyEQSuQPYCtS5+wl3HwBeArbHLuDuLe5+ABgcU97k7oeD791EXyq/PCk1n+UGhkbYWxth2zWLycqc3kzbuvJC7txQxvd/e5Kfv9XEosJcNlcUTes+RWTuS+TMtBxoiJluZAoncTNbBdwI/C6m+HEze8vMnjez4ius94iZHTSzg62trZPdbcrsP9FOV9/QtLT+ieeLd6yhrWeAPbUR7r6mXIO/iciEEgkA8c4kk3ollZkVAj8GvuruXUHx08BaYDPQBHwr3rru/qy7V7l7VVnZ5F6jmEq7qpvJz8nkjvWLZmR/t64tZeOSaEcztf4RkUQkEgAagcqY6Qog/vgDcZhZNtGT/4vu/pPRcnePuPuwu48A3yWaakoLIyPO7poIH9swc+PwmBl/9fEN3FCxkNtnKOiIyNyWyItpDwDrzWw1cBp4APhcIhu3aNvH54Bad/+HMfOWuntTMPlp4J2Eaz3LvdHQSUt3/4ylf0bds2mxHv6KSMImDADuPmRmjwO7gEzgeXevNrNHg/nPmNkS4CCwABgxs68SbTF0PfAg8LaZHQk2+XdBi59vmNlmoumkk8CXkvi7UmpXdTPZmcadGodHRGaxRO4ACE7YO8eUPRPzvZloamis14n/DAF3fzDxas4d7s6u6mZuXbuIBfOyU10dEZErUk/gJDsW6aG+vXfG0z8iIpOlAJBkrx2LNlXVMMwiMtspACTZa8dbWV9eyJKF81JdFRGRcSkAJFHf4DC/f/+smmGKyJygAJBEB0920D80wkfWz50OayISXgoASbTveCvZmcZNa6Z38DcRkWRQAEiifcfb+PDKYvJzEmpdKyKSUgoASdLa3U9NUxd3KP0jInOEAkCS/Oa96IvZZ2rwNxGRq6UAkCSvHWujOD+ba5cl/92/IiLTQQEgCdydfcdbuXXdIjI1Dr+IzBEKAElwvKWHlu5+PqL0j4jMIQoASTA6/MPtegAsInOIAkASvF7XxpqyApYX5aW6KiIiCVMAuEr9Q8PsP9Gu3r8iMucoAFylQyc76Bsc4fZ1yv+LyNyiAHCV9tW1kZVh3Ly2NNVVERGZFAWAq7TveCtbVhRTmKvhH0RkbkkoAJjZfWZ21MzqzOyJOPM3mtlvzazfzL6WyLpmVmJmu83sePBZfPU/Z2a19/RTfaZLvX9FZE6aMACYWSbwFHA/0Re9f9bMNo1Z7CzwZeCbk1j3CWCvu68H9gbTc8q/vdeOO9zxIT0AFpG5J5E7gK1AnbufcPcB4CVge+wC7t7i7geAwUmsux14Ifj+AvCpqf2E1Nl3rJWFedlct1zDP4jI3JNIAFgONMRMNwZliRhv3cXu3gQQfMZ9ia6ZPWJmB83sYGtra4K7nX7uzut1bdy2rlTDP4jInJRIAIh3dvMEt38160YXdn/W3avcvaqsbPakWt5r7aHpXB+3r5s9dRIRmYxEAkAjUBkzXQGcSXD7460bMbOlAMFnS4LbnBX2HdfwzyIytyUSAA4A681stZnlAA8AOxLc/njr7gAeCr4/BPws8Wqn3r7jbawqzaeyJD/VVRERmZIJG6+7+5CZPQ7sAjKB59292sweDeY/Y2ZLgIPAAmDEzL4KbHL3rnjrBpt+EnjZzB4GTgGfSfJvmzYDQyPsP9HOH2+pSHVVRESmLKHeS+6+E9g5puyZmO/NRNM7Ca0blLcD2yZT2dmipqmL3oFhbl6j3r8iMnepJ/AUHKrvAKBq1ZzruyYicpECwBQcPtXB8qI8Fi+Yl+qqiIhMmQLAFByu72DLSl39i8jcpgAwSWc6L9B0ro8tK4pSXRURkauiADBJh09F8/8f1h2AiMxxCgCTdLi+k3nZGVyzdEGqqyIiclUUACbp0KkOrq8oIjtTh05E5jadxSahb3CY6tPn2LJC6R8RmfsUACbh7dPnGBpx5f9FJC0oAEzCaAcwtQASkXSgADAJh+s7WFWaT2lhbqqrIiJy1RQAEuTuHD6lDmAikj4UABLUcPYCbT0DegAsImlDASBBh06dBdQBTETShwJAgg7Xd1KYm8WHFs9PdVVERJJCASBBh+o72FxZpBfAi0jaUABIwPn+Id5t7lLzTxFJKwkFADO7z8yOmlmdmT0RZ76Z2XeC+W+Z2ZagfIOZHYn56wpeF4mZfd3MTsfM+0RSf1kSvdnQyYijFkAiklYmfCWkmWUCTwH3AI3AATPb4e41MYvdD6wP/m4CngZucvejwOaY7ZwGfhqz3rfd/ZtJ+B3TanQE0BsrFQBEJH0kcgewFahz9xPuPgC8BGwfs8x24PsetR8oMrOlY5bZBrzn7vVXXesZdqi+g/XlhSzMz051VUREkiaRALAcaIiZbgzKJrvMA8APx5Q9HqSMnjezuJfXZvaImR00s4Otra0JVDe5Rkacw6c61fxTRNJOIgEgXrMXn8wyZpYDfBL4Ucz8p4G1RFNETcC34u3c3Z919yp3ryorK0ugusl1ou085y4MqgOYiKSdRAJAI1AZM10BnJnkMvcDh909Mlrg7hF3H3b3EeC7RFNNs87h0QHgdAcgImkmkQBwAFhvZquDK/kHgB1jltkB/EXQGuhm4Jy7N8XM/yxj0j9jnhF8Gnhn0rWfAYdPdbAwL5s1iwpSXRURkaSasBWQuw+Z2ePALiATeN7dq83s0WD+M8BO4BNAHdALfH50fTPLJ9qC6EtjNv0NM9tMNFV0Ms78WeFQfQdbVhSRoQ5gIpJmJgwAAO6+k+hJPrbsmZjvDjx2hXV7gdI45Q9OqqYpcO7CIMdbevjkDctSXRURkaRTT+BxvBG0/1cLIBFJRwoA4zh8qpMMgxsqi1JdFRGRpFMAGMfh+g42LllAQW5CmTIRkTlFAeAK3jl9jt+9387Nay57fCEikhYUAOLoHRjiyz98g9KCXL68bV2qqyMiMi2U24jj739ew/vt53nxizdRlJ+T6uqIiEwL3QGM8Yt3mvnh7xv40kfWcuvaRamujojItFEAiNHS3ccTP3mL65Yv5C/v+VCqqyMiMq2UAorxq6OtdPYO8oOHryMnS7FRRNKbznIx6tvPk5VhbFyiF7+LSPpTAIhxsr2XiuI8sjJ1WEQk/elMF6O+/TwrSzXqp4iEgwJAwN2pb+tlVWl+qqsiIjIjFAACHb2DdPcPsUJ3ACISEgoAgZPt5wF0ByAioaEAEKgPAoCeAYhIWCgABE629WIGlSV5qa6KiMiMSCgAmNl9ZnbUzOrM7Ik4883MvhPMf8vMtsTMO2lmb5vZETM7GFNeYma7zex48JnSt66cOtvLsoV55GZlprIaIiIzZsIAYGaZwFPA/cAm4LNmtmnMYvcD64O/R4Cnx8y/0903u3tVTNkTwF53Xw/sDaZT5mT7eVYq/y8iIZLIHcBWoM7dT7j7APASsH3MMtuB73vUfqDIzJZOsN3twAvB9xeATyVe7eSrb+9V/l9EQiWRALAcaIiZbgzKEl3GgVfM7JCZPRKzzGJ3bwIIPsvj7dzMHjGzg2Z2sLW1NYHqTt65C4OcPT+gFkAiEiqJBACLU+aTWOY2d99CNE30mJl9ZBL1w92fdfcqd68qKyubzKoJO9XeC6gFkIiESyIBoBGojJmuAM4kuoy7j362AD8lmlICiIymiYLPlslWPlnqz442AdUdgIiERyIB4ACw3sxWm1kO8ACwY8wyO4C/CFoD3Qycc/cmMysws/kAZlYAfBx4J2adh4LvDwE/u8rfMmX1F+8AFABEJDwmfB+Auw+Z2ePALiATeN7dq83s0WD+M8BO4BNAHdALfD5YfTHwUzMb3de/uPsvgnlPAi+b2cPAKeAzSftVk3Sy7Tzl83PJz9HrEUQkPBI647n7TqIn+diyZ2K+O/BYnPVOADdcYZvtwLbJVHa61Lf3skr5fxEJGfUEJvoMQOkfEQmb0AeA3oEhIl39CgAiEjqhDwCnzqoJqIiEU+gDwMm2aADQMwARCZvQB4BTQR+AFUoBiUjIhD4AnGzvpaQgh4V52amuiojIjAp9ADjR2qMHwCISSqEOAMMjztuN57hu+cJUV0VEZMaFOgAci3RzfmCYG1cUpboqIiIzLtQB4PCpDgC2rEjpy8hERFIi3AGgvpPSghxWlOgZgIiET6gDwBunOrhxRTHBYHUiIqES2gDQcX6AE23n2bKyKNVVERFJidAGgDcalP8XkXALbQA4XN9JZoZxfYWagIpIOIU3AJzq4Jql8/USGBEJrVAGgOER582GTqV/RCTUEgoAZnafmR01szozeyLOfDOz7wTz3zKzLUF5pZm9ama1ZlZtZl+JWefrZnbazI4Ef59I3s8a32gHMAUAEQmzCfMfZpYJPAXcAzQCB8xsh7vXxCx2P7A++LsJeDr4HAL+yt0PBy+HP2Rmu2PW/ba7fzN5Pycx6gAmIpLYHcBWoM7dT7j7APASsH3MMtuB73vUfqDIzJa6e5O7HwZw926gFliexPpPyWgHsMqSvFRXRUQkZRIJAMuBhpjpRi4/iU+4jJmtAm4EfhdT/HiQMnrezKbtctzdaevpZ2TEAXUAExGBBFJAQLyzpE9mGTMrBH4MfNXdu4Lip4G/D5b7e+BbwBcu27nZI8AjACtWrEigupf7zt46vr3nGFkZxuIF8zjdeYE/qaqY0rZERNJFIgGgEaiMma4AziS6jJllEz35v+juPxldwN0jo9/N7LvAz+Pt3N2fBZ4FqKqqGht4EtLW009ediZfuH0VTZ19dF4Y5A+vWzaVTYmIpI1EAsABYL2ZrQZOAw8AnxuzzA6i6ZyXiD78PefuTRbNsTwH1Lr7P8SuMPqMIJj8NPDOVfyOCeXlZPJf7t04nbsQEZlTJgwA7j5kZo8Du4BM4Hl3rzazR4P5zwA7gU8AdUAv8Plg9duAB4G3zexIUPZ37r4T+IaZbSaaAjoJfClJv0lERBKQUDfY4IS9c0zZMzHfHXgsznqvE//5AO7+4KRqehWuXbaA/qHhmdqdiMicEIpxEB7YuoIHtk7tAbKISLoK5VAQIiKiACAiEloKACIiIaUAICISUgoAIiIhpQAgIhJSCgAiIiGlACAiElIW7cQ7N5hZK1A/iVUWAW3TVJ25SMfjcjoml9LxuFS6HI+V7l42tnBOBYDJMrOD7l6V6nrMFjoel9MxuZSOx6XS/XgoBSQiElIKACIiIZXuAeDZVFdgltHxuJyOyaV0PC6V1scjrZ8BiIjIlaX7HYCIiFyBAoCISEilZQAws/vM7KiZ1ZnZE6muz0wws0oze9XMas2s2sy+EpSXmNluMzsefBbHrPO3wTE6amb3pq7208fMMs3sDTP7eTAd9uNRZGb/ambvBv+v3BLmY2Jm/zn49/KOmf3QzOaF6ni4e1r9EX1v8XvAGiAHeBPYlOp6zcDvXgpsCb7PB44Bm4BvAE8E5U8A/z34vik4NrnA6uCYZab6d0zDcflL4F+AnwfTYT8eLwBfDL7nAEVhPSbAcuB9IC+Yfhn4D2E6Hul4B7AVqHP3E+4+ALwEbE9xnaaduze5++HgezdQS/R/8O1E/9ETfH4q+L4deMnd+939faCO6LFLG2ZWAfx74HsxxWE+HguAjwDPAbj7gLt3EuJjQvS1uHlmlgXkA2cI0fFIxwCwHGiImW4MykLDzFYBNwK/Axa7exNEgwRQHiwWhuP0j8BfAyMxZWE+HmuAVuB/BWmx75lZASE9Ju5+GvgmcApoAs65+yuE6HikYwCwOGWhaetqZoXAj4GvunvXeIvGKUub42Rmfwi0uPuhRFeJU5Y2xyOQBWwBnnb3G4HzRFMcV5LWxyTI7W8nms5ZBhSY2Z+Pt0qcsjl9PNIxADQClTHTFURv69KemWUTPfm/6O4/CYojZrY0mL8UaAnK0/043QZ80sxOEk0D3mVmPyC8xwOiv7HR3X8XTP8r0YAQ1mNyN/C+u7e6+yDwE+BWQnQ80jEAHADWm9lqM8sBHgB2pLhO087MjGhut9bd/yFm1g7goeD7Q8DPYsofMLNcM1sNrAd+P1P1nW7u/rfuXuHuq4j+P/BLd/9zQno8ANy9GWgwsw1B0TaghvAek1PAzWaWH/z72Ub02VlojkdWqiuQbO4+ZGaPA7uItgh63t2rU1ytmXAb8CDwtpkdCcr+DngSeNnMHib6P/xnANy92sxeJnoCGAIec/fhGa/1zAv78fhPwIvBxdEJ4PNELwRDd0zc/Xdm9q/AYaK/7w2iQz8UEpLjoaEgRERCKh1TQCIikgAFABGRkFIAEBEJKQUAEZGQUgAQEQkpBQARkZBSABARCan/D+pZaShR8cudAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['n_pca'], results['r2 score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: сокращение размерности с помощью PCA существенно ухудшает качество модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
